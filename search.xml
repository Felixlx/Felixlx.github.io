<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>aws load balancer installation</title>
      <link href="/2023/07/07/aws-load-balancer-installation/"/>
      <url>/2023/07/07/aws-load-balancer-installation/</url>
      
        <content type="html"><![CDATA[<h2 id="install-with-script"><a href="#install-with-script" class="headerlink" title="install with script"></a>install with script</h2><pre class="line-numbers language-none"><code class="language-none">#!/bin/bash: this sh is for installation of aws lb controllerecho "install aws lb controller"export clusterName=felix-tfcexport seed=${RANDOM}export policyname=AWSLoadBalancerControllerIAMPolicy${seed}echo "create iam policy"aws iam create-policy --policy-name $policyname --policy-document file://iam_policy_cn.json --no-cli-pagerpolicyarn=$(aws iam list-policies --query "Policies[?PolicyName==\`${policyname}\`].Arn" --output text --no-cli-pager)export policyarneksctl utils associate-iam-oidc-provider --region=cn-north-1 --cluster=felix-tfc --approveaws cloudformation delete-stack --stack-name eksctl-felix-tfc-addon-iamserviceaccount-kube-system-aws-load-balancer-controller || trueecho "will sleep 200 for cfn deletion"sleep 200eksctl create iamserviceaccount \  --cluster=${clusterName} \  --namespace=kube-system \  --name=aws-load-balancer-controller \  --role-name AmazonEKSLoadBalancerControllerRole${seed} \  --attach-policy-arn="${policyarn}" \  --override-existing-serviceaccounts \  --approvehelm repo add eks https://aws.github.io/eks-chartshelm repo updatehelm install aws-load-balancer-controller eks/aws-load-balancer-controller \  -n kube-system \  --set clusterName=${clusterName} \  --set serviceAccount.create=false \  --set serviceAccount.name=aws-load-balancer-controller \  --set enableShield=false \  --set enableWaf=false \  --set enableWafv2=falseecho testingkubectl get deployment -n kube-system aws-load-balancer-controller<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> eks </category>
          
      </categories>
      
      
        <tags>
            
            <tag> eks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>eks bootstrap.sh</title>
      <link href="/2023/07/06/eks-bootstrap-sh/"/>
      <url>/2023/07/06/eks-bootstrap-sh/</url>
      
        <content type="html"><![CDATA[<h2 id="bootstrap-sh-explaining"><a href="#bootstrap-sh-explaining" class="headerlink" title="bootstrap.sh explaining"></a>bootstrap.sh explaining</h2><p>login a node and find the script at /etc/eks/</p><pre class="line-numbers language-none"><code class="language-none">#!/usr/bin/env bashset -o pipefailset -o nounsetset -o errexiterr_report() {  echo "Exited with error on line $1"}trap 'err_report $LINENO' ERRIFS=$'\n\t'# mute stdout from vercmpexport VERCMP_QUIET=truefunction print_help {  echo "usage: $0 [options] &lt;cluster-name&gt;"  echo "Bootstraps an instance into an EKS cluster"  echo ""  echo "-h,--help print this help"  echo  echo "--apiserver-endpoint The EKS cluster API Server endpoint. Only valid when used with --b64-cluster-ca. Bypasses calling \"aws eks describe-cluster\""  echo "--aws-api-retry-attempts Number of retry attempts for AWS API call (DescribeCluster) (default: 3)"  echo "--b64-cluster-ca The base64 encoded cluster CA content. Only valid when used with --apiserver-endpoint. Bypasses calling \"aws eks describe-cluster\""  echo "--cluster-id Specify the id of EKS cluster"  echo "--container-runtime Specify a container runtime. For Kubernetes 1.23 and below, possible values are [dockerd, containerd] and the default value is dockerd. For Kubernetes 1.24 and above, containerd is the only valid value. This flag is deprecated and will be removed in a future release."  echo "--containerd-config-file File containing the containerd configuration to be used in place of AMI defaults."  echo "--dns-cluster-ip Overrides the IP address to use for DNS queries within the cluster. Defaults to 10.100.0.10 or 172.20.0.10 based on the IP address of the primary interface"  echo "--docker-config-json The contents of the /etc/docker/daemon.json file. Useful if you want a custom config differing from the default one in the AMI"  echo "--enable-docker-bridge Restores the docker default bridge network. (default: false)"  echo "--enable-local-outpost Enable support for worker nodes to communicate with the local control plane when running on a disconnected Outpost. (true or false)"  echo "--ip-family Specify ip family of the cluster"  echo "--kubelet-extra-args Extra arguments to add to the kubelet. Useful for adding labels or taints."  echo "--local-disks Setup instance storage NVMe disks in raid0 or mount the individual disks for use by pods [mount | raid0]"  echo "--mount-bpf-fs Mount a bpffs at /sys/fs/bpf (default: true, for Kubernetes 1.25+; false otherwise)"  echo "--pause-container-account The AWS account (number) to pull the pause container from"  echo "--pause-container-version The tag of the pause container"  echo "--service-ipv6-cidr ipv6 cidr range of the cluster"  echo "--use-max-pods Sets --max-pods for the kubelet when true. (default: true)"}function log {  echo &gt;&amp;2 "$(date '+%Y-%m-%dT%H:%M:%S%z')" "[eks-bootstrap]" "$@"}log "INFO: starting..."POSITIONAL=()while [[ $# -gt 0 ]]; do  key="$1"  case $key in    -h | --help)      print_help      exit 1      ;;    --use-max-pods)      USE_MAX_PODS="$2"      log "INFO: --use-max-pods='${USE_MAX_PODS}'"      shift      shift      ;;    --b64-cluster-ca)      B64_CLUSTER_CA=$2      log "INFO: --b64-cluster-ca='${B64_CLUSTER_CA}'"      shift      shift      ;;    --apiserver-endpoint)      APISERVER_ENDPOINT=$2      log "INFO: --apiserver-endpoint='${APISERVER_ENDPOINT}'"      shift      shift      ;;    --kubelet-extra-args)      KUBELET_EXTRA_ARGS=$2      log "INFO: --kubelet-extra-args='${KUBELET_EXTRA_ARGS}'"      shift      shift      ;;    --enable-docker-bridge)      ENABLE_DOCKER_BRIDGE=$2      log "INFO: --enable-docker-bridge='${ENABLE_DOCKER_BRIDGE}'"      shift      shift      ;;    --aws-api-retry-attempts)      API_RETRY_ATTEMPTS=$2      log "INFO: --aws-api-retry-attempts='${API_RETRY_ATTEMPTS}'"      shift      shift      ;;    --docker-config-json)      DOCKER_CONFIG_JSON=$2      log "INFO: --docker-config-json='${DOCKER_CONFIG_JSON}'"      shift      shift      ;;    --containerd-config-file)      CONTAINERD_CONFIG_FILE=$2      log "INFO: --containerd-config-file='${CONTAINERD_CONFIG_FILE}'"      shift      shift      ;;    --pause-container-account)      PAUSE_CONTAINER_ACCOUNT=$2      log "INFO: --pause-container-account='${PAUSE_CONTAINER_ACCOUNT}'"      shift      shift      ;;    --pause-container-version)      PAUSE_CONTAINER_VERSION=$2      log "INFO: --pause-container-version='${PAUSE_CONTAINER_VERSION}'"      shift      shift      ;;    --dns-cluster-ip)      DNS_CLUSTER_IP=$2      log "INFO: --dns-cluster-ip='${DNS_CLUSTER_IP}'"      shift      shift      ;;    --container-runtime)      CONTAINER_RUNTIME=$2      log "INFO: --container-runtime='${CONTAINER_RUNTIME}'"      shift      shift      ;;    --ip-family)      IP_FAMILY=$2      log "INFO: --ip-family='${IP_FAMILY}'"      shift      shift      ;;    --service-ipv6-cidr)      SERVICE_IPV6_CIDR=$2      log "INFO: --service-ipv6-cidr='${SERVICE_IPV6_CIDR}'"      shift      shift      ;;    --enable-local-outpost)      ENABLE_LOCAL_OUTPOST=$2      log "INFO: --enable-local-outpost='${ENABLE_LOCAL_OUTPOST}'"      shift      shift      ;;    --cluster-id)      CLUSTER_ID=$2      log "INFO: --cluster-id='${CLUSTER_ID}'"      shift      shift      ;;    --mount-bpf-fs)      MOUNT_BPF_FS=$2      log "INFO: --mount-bpf-fs='${MOUNT_BPF_FS}'"      shift      shift      ;;    --local-disks)      LOCAL_DISKS=$2      log "INFO: --local-disks='${LOCAL_DISKS}'"      shift      shift      ;;    *)                   # unknown option      POSITIONAL+=("$1") # save it in an array for later      shift              # past argument      ;;  esacdoneset +uset -- "${POSITIONAL[@]}" # restore positional parametersCLUSTER_NAME="$1"set -uKUBELET_VERSION=$(kubelet --version | grep -Eo '[0-9]\.[0-9]+\.[0-9]+')log "INFO: Using kubelet version $KUBELET_VERSION"# ecr-credential-provider only implements credentialprovider.kubelet.k8s.io/v1alpha1 prior to 1.27.1: https://github.com/kubernetes/cloud-provider-aws/pull/597# TODO: remove this when 1.26 is EOLif vercmp "$KUBELET_VERSION" lt "1.27.0"; then  IMAGE_CREDENTIAL_PROVIDER_CONFIG=/etc/eks/image-credential-provider/config.json  echo "$(jq '.apiVersion = "kubelet.config.k8s.io/v1alpha1"' $IMAGE_CREDENTIAL_PROVIDER_CONFIG)" &gt; $IMAGE_CREDENTIAL_PROVIDER_CONFIG  echo "$(jq '.providers[].apiVersion = "credentialprovider.kubelet.k8s.io/v1alpha1"' $IMAGE_CREDENTIAL_PROVIDER_CONFIG)" &gt; $IMAGE_CREDENTIAL_PROVIDER_CONFIGfi# Set container runtime related variablesDOCKER_CONFIG_JSON="${DOCKER_CONFIG_JSON:-}"ENABLE_DOCKER_BRIDGE="${ENABLE_DOCKER_BRIDGE:-false}"# As of Kubernetes version 1.24, we will start defaulting the container runtime to containerd# and no longer support docker as a container runtime.DEFAULT_CONTAINER_RUNTIME=dockerdif vercmp "$KUBELET_VERSION" gteq "1.24.0"; then  DEFAULT_CONTAINER_RUNTIME=containerdfiCONTAINER_RUNTIME="${CONTAINER_RUNTIME:-$DEFAULT_CONTAINER_RUNTIME}"log "INFO: Using $CONTAINER_RUNTIME as the container runtime"if vercmp "$KUBELET_VERSION" gteq "1.24.0" &amp;&amp; [ $CONTAINER_RUNTIME != "containerd" ]; then  log "ERROR: containerd is the only supported container runtime as of Kubernetes version 1.24"  exit 1fiUSE_MAX_PODS="${USE_MAX_PODS:-true}"B64_CLUSTER_CA="${B64_CLUSTER_CA:-}"APISERVER_ENDPOINT="${APISERVER_ENDPOINT:-}"SERVICE_IPV4_CIDR="${SERVICE_IPV4_CIDR:-}"DNS_CLUSTER_IP="${DNS_CLUSTER_IP:-}"KUBELET_EXTRA_ARGS="${KUBELET_EXTRA_ARGS:-}"API_RETRY_ATTEMPTS="${API_RETRY_ATTEMPTS:-3}"CONTAINERD_CONFIG_FILE="${CONTAINERD_CONFIG_FILE:-}"PAUSE_CONTAINER_VERSION="${PAUSE_CONTAINER_VERSION:-3.5}"IP_FAMILY="${IP_FAMILY:-}"SERVICE_IPV6_CIDR="${SERVICE_IPV6_CIDR:-}"ENABLE_LOCAL_OUTPOST="${ENABLE_LOCAL_OUTPOST:-}"CLUSTER_ID="${CLUSTER_ID:-}"LOCAL_DISKS="${LOCAL_DISKS:-}"if [[ ! -z ${LOCAL_DISKS} ]]; then  setup-local-disks "${LOCAL_DISKS}"fiDEFAULT_MOUNT_BPF_FS="true"if vercmp "$KUBELET_VERSION" lt "1.25.0"; then  DEFAULT_MOUNT_BPF_FS="false"fiMOUNT_BPF_FS="${MOUNT_BPF_FS:-$DEFAULT_MOUNT_BPF_FS}"# Helper function which calculates the amount of the given resource (either CPU or memory)# to reserve in a given resource range, specified by a start and end of the range and a percentage# of the resource to reserve. Note that we return zero if the start of the resource range is# greater than the total resource capacity on the node. Additionally, if the end range exceeds the total# resource capacity of the node, we use the total resource capacity as the end of the range.# Args:#   $1 total available resource on the worker node in input unit (either millicores for CPU or Mi for memory)#   $2 start of the resource range in input unit#   $3 end of the resource range in input unit#   $4 percentage of range to reserve in percent*100 (to allow for two decimal digits)# Return:#   amount of resource to reserve in input unitget_resource_to_reserve_in_range() {  local total_resource_on_instance=$1  local start_range=$2  local end_range=$3  local percentage=$4  resources_to_reserve="0"  if (($total_resource_on_instance &gt; $start_range)); then    resources_to_reserve=$(((($total_resource_on_instance &lt; $end_range ? $total_resource_on_instance : $end_range) - $start_range) * $percentage / 100 / 100))  fi  echo $resources_to_reserve}# Calculates the amount of memory to reserve for kubeReserved in mebibytes. KubeReserved is a function of pod# density so we are calculating the amount of memory to reserve for Kubernetes systems daemons by# considering the maximum number of pods this instance type supports.# Args:#   $1 the max number of pods per instance type (MAX_PODS) based on values from /etc/eks/eni-max-pods.txt# Return:#   memory to reserve in Mi for the kubeletget_memory_mebibytes_to_reserve() {  local max_num_pods=$1  memory_to_reserve=$((11 * $max_num_pods + 255))  echo $memory_to_reserve}# Calculates the amount of CPU to reserve for kubeReserved in millicores from the total number of vCPUs available on the instance.# From the total core capacity of this worker node, we calculate the CPU resources to reserve by reserving a percentage# of the available cores in each range up to the total number of cores available on the instance.# We are using these CPU ranges from GKE (https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture#node_allocatable):# 6% of the first core# 1% of the next core (up to 2 cores)# 0.5% of the next 2 cores (up to 4 cores)# 0.25% of any cores above 4 cores# Return:#   CPU resources to reserve in millicores (m)get_cpu_millicores_to_reserve() {  local total_cpu_on_instance=$(($(nproc) * 1000))  local cpu_ranges=(0 1000 2000 4000 $total_cpu_on_instance)  local cpu_percentage_reserved_for_ranges=(600 100 50 25)  cpu_to_reserve="0"  for i in "${!cpu_percentage_reserved_for_ranges[@]}"; do    local start_range=${cpu_ranges[$i]}    local end_range=${cpu_ranges[(($i + 1))]}    local percentage_to_reserve_for_range=${cpu_percentage_reserved_for_ranges[$i]}    cpu_to_reserve=$(($cpu_to_reserve + $(get_resource_to_reserve_in_range $total_cpu_on_instance $start_range $end_range $percentage_to_reserve_for_range)))  done  echo $cpu_to_reserve}if [ -z "$CLUSTER_NAME" ]; then  log "ERROR: cluster name is not defined!"  exit 1fiif [[ ! -z "${IP_FAMILY}" ]]; then  IP_FAMILY="$(tr [A-Z] [a-z] &lt;&lt;&lt; "$IP_FAMILY")"  if [[ "${IP_FAMILY}" != "ipv4" ]] &amp;&amp; [[ "${IP_FAMILY}" != "ipv6" ]]; then    log "ERROR: Invalid --ip-family. Only ipv4 or ipv6 are allowed"    exit 1  fifiif [[ ! -z "${SERVICE_IPV6_CIDR}" ]]; then  if [[ "${IP_FAMILY}" == "ipv4" ]]; then    log "ERROR: --ip-family should be ipv6 when --service-ipv6-cidr is specified"    exit 1  fi  IP_FAMILY="ipv6"fiAWS_DEFAULT_REGION=$(imds 'latest/dynamic/instance-identity/document' | jq .region -r)AWS_SERVICES_DOMAIN=$(imds 'latest/meta-data/services/domain')MACHINE=$(uname -m)if [[ "$MACHINE" != "x86_64" &amp;&amp; "$MACHINE" != "aarch64" ]]; then  log "ERROR: Unknown machine architecture: '$MACHINE'"  exit 1fiif [ "$MOUNT_BPF_FS" = "true" ]; then  mount-bpf-fsficp -v /etc/eks/configure-clocksource.service /etc/systemd/system/configure-clocksource.servicechown root:root /etc/systemd/system/configure-clocksource.servicesystemctl daemon-reloadsystemctl enable --now configure-clocksourceECR_URI=$(/etc/eks/get-ecr-uri.sh "${AWS_DEFAULT_REGION}" "${AWS_SERVICES_DOMAIN}" "${PAUSE_CONTAINER_ACCOUNT:-}")PAUSE_CONTAINER_IMAGE=${PAUSE_CONTAINER_IMAGE:-$ECR_URI/eks/pause}PAUSE_CONTAINER="$PAUSE_CONTAINER_IMAGE:$PAUSE_CONTAINER_VERSION"### kubelet kubeconfigCA_CERTIFICATE_DIRECTORY=/etc/kubernetes/pkiCA_CERTIFICATE_FILE_PATH=$CA_CERTIFICATE_DIRECTORY/ca.crtmkdir -p $CA_CERTIFICATE_DIRECTORYif [[ -z "${B64_CLUSTER_CA}" ]] || [[ -z "${APISERVER_ENDPOINT}" ]]; then  log "INFO: --cluster-ca or --api-server-endpoint is not defined, describing cluster..."  DESCRIBE_CLUSTER_RESULT="/tmp/describe_cluster_result.txt"  # Retry the DescribeCluster API for API_RETRY_ATTEMPTS  for attempt in $(seq 0 $API_RETRY_ATTEMPTS); do    rc=0    if [[ $attempt -gt 0 ]]; then      log "INFO: Attempt $attempt of $API_RETRY_ATTEMPTS"    fi    aws eks wait cluster-active \      --region=${AWS_DEFAULT_REGION} \      --name=${CLUSTER_NAME}    aws eks describe-cluster \      --region=${AWS_DEFAULT_REGION} \      --name=${CLUSTER_NAME} \      --output=text \      --query 'cluster.{certificateAuthorityData: certificateAuthority.data, endpoint: endpoint, serviceIpv4Cidr: kubernetesNetworkConfig.serviceIpv4Cidr, serviceIpv6Cidr: kubernetesNetworkConfig.serviceIpv6Cidr, clusterIpFamily: kubernetesNetworkConfig.ipFamily, outpostArn: outpostConfig.outpostArns[0], id: id}' &gt; $DESCRIBE_CLUSTER_RESULT || rc=$?    if [[ $rc -eq 0 ]]; then      break    fi    if [[ $attempt -eq $API_RETRY_ATTEMPTS ]]; then      log "ERROR: Exhausted retries while describing cluster!"      exit $rc    fi    jitter=$((1 + RANDOM % 10))    sleep_sec="$(($((5 &lt;&lt; $((1 + $attempt)))) + $jitter))"    sleep $sleep_sec  done  B64_CLUSTER_CA=$(cat $DESCRIBE_CLUSTER_RESULT | awk '{print $1}')  APISERVER_ENDPOINT=$(cat $DESCRIBE_CLUSTER_RESULT | awk '{print $3}')  CLUSTER_ID_IN_DESCRIBE_CLUSTER_RESULT=$(cat $DESCRIBE_CLUSTER_RESULT | awk '{print $4}')  OUTPOST_ARN=$(cat $DESCRIBE_CLUSTER_RESULT | awk '{print $5}')  SERVICE_IPV4_CIDR=$(cat $DESCRIBE_CLUSTER_RESULT | awk '{print $6}')  SERVICE_IPV6_CIDR=$(cat $DESCRIBE_CLUSTER_RESULT | awk '{print $7}')  if [[ -z "${IP_FAMILY}" ]]; then    IP_FAMILY=$(cat $DESCRIBE_CLUSTER_RESULT | awk '{print $2}')  fi  # Automatically detect local cluster in outpost  if [[ -z "${OUTPOST_ARN}" ]] || [[ "${OUTPOST_ARN}" == "None" ]]; then    IS_LOCAL_OUTPOST_DETECTED=false  else    IS_LOCAL_OUTPOST_DETECTED=true  fi  # If the cluster id is returned from describe cluster, let us use it no matter whether cluster id is passed from option  if [[ ! -z "${CLUSTER_ID_IN_DESCRIBE_CLUSTER_RESULT}" ]] &amp;&amp; [[ "${CLUSTER_ID_IN_DESCRIBE_CLUSTER_RESULT}" != "None" ]]; then    CLUSTER_ID=${CLUSTER_ID_IN_DESCRIBE_CLUSTER_RESULT}  fifiif [[ -z "${IP_FAMILY}" ]] || [[ "${IP_FAMILY}" == "None" ]]; then  ### this can happen when the ipFamily field is not found in describeCluster response  ### or B64_CLUSTER_CA and APISERVER_ENDPOINT are defined but IPFamily isn't  IP_FAMILY="ipv4"filog "INFO: Using IP family: ${IP_FAMILY}"echo $B64_CLUSTER_CA | base64 -d &gt; $CA_CERTIFICATE_FILE_PATHsed -i s,MASTER_ENDPOINT,$APISERVER_ENDPOINT,g /var/lib/kubelet/kubeconfigsed -i s,AWS_REGION,$AWS_DEFAULT_REGION,g /var/lib/kubelet/kubeconfigif [[ -z "$ENABLE_LOCAL_OUTPOST" ]]; then  # Only when "--enable-local-outpost" option is not set explicity on calling bootstrap.sh, it will be assigned with  #    - the result of auto-detectection through describe-cluster  #    - or "false" when describe-cluster is bypassed.  #  This also means if "--enable-local-outpost" option is set explicity, it will override auto-detection result  ENABLE_LOCAL_OUTPOST="${IS_LOCAL_OUTPOST_DETECTED:-false}"fi### To support worker nodes to continue to communicate and connect to local cluster even when the Outpost### is disconnected from the parent AWS Region, the following specific setup are required:###    - append entries to /etc/hosts with the mappings of control plane host IP address and API server###      domain name. So that the domain name can be resolved to IP addresses locally.###    - use aws-iam-authenticator as bootstrap auth for kubelet TLS bootstrapping which downloads client###      X.509 certificate and generate kubelet kubeconfig file which uses the client cert. So that the###      worker node can be authentiacated through X.509 certificate which works for both connected and####     disconnected state.if [[ "${ENABLE_LOCAL_OUTPOST}" == "true" ]]; then  ### append to /etc/hosts file with shuffled mappings of "IP address to API server domain name"  DOMAIN_NAME=$(echo "$APISERVER_ENDPOINT" | awk -F/ '{print $3}' | awk -F: '{print $1}')  getent hosts "$DOMAIN_NAME" | shuf &gt;&gt; /etc/hosts  ### kubelet bootstrap kubeconfig uses aws-iam-authenticator with cluster id to authenticate to cluster  ###   - if "aws eks describe-cluster" is bypassed, for local outpost, the value of CLUSTER_NAME parameter will be cluster id.  ###   - otherwise, the cluster id will use the id returned by "aws eks describe-cluster".  if [[ -z "${CLUSTER_ID}" ]]; then    log "ERROR: Cluster ID is required when local outpost support is enabled"    exit 1  else    sed -i s,CLUSTER_NAME,$CLUSTER_ID,g /var/lib/kubelet/kubeconfig    ### use aws-iam-authenticator as bootstrap auth and download X.509 cert used in kubelet kubeconfig    mv /var/lib/kubelet/kubeconfig /var/lib/kubelet/bootstrap-kubeconfig    KUBELET_EXTRA_ARGS="--bootstrap-kubeconfig /var/lib/kubelet/bootstrap-kubeconfig $KUBELET_EXTRA_ARGS"  fielse  sed -i s,CLUSTER_NAME,$CLUSTER_NAME,g /var/lib/kubelet/kubeconfigfi### kubelet.service configurationMAC=$(imds 'latest/meta-data/mac')if [[ -z "${DNS_CLUSTER_IP}" ]]; then  if [[ "${IP_FAMILY}" == "ipv6" ]]; then    if [[ -z "${SERVICE_IPV6_CIDR}" ]]; then      log "ERROR: One of --service-ipv6-cidr or --dns-cluster-ip must be provided when --ip-family is ipv6"      exit 1    fi    DNS_CLUSTER_IP=$(awk -F/ '{print $1}' &lt;&lt;&lt; $SERVICE_IPV6_CIDR)a  fi  if [[ "${IP_FAMILY}" == "ipv4" ]]; then    if [[ ! -z "${SERVICE_IPV4_CIDR}" ]] &amp;&amp; [[ "${SERVICE_IPV4_CIDR}" != "None" ]]; then      #Sets the DNS Cluster IP address that would be chosen from the serviceIpv4Cidr. (x.y.z.10)      DNS_CLUSTER_IP=${SERVICE_IPV4_CIDR%.*}.10    else      TEN_RANGE=$(imds "latest/meta-data/network/interfaces/macs/$MAC/vpc-ipv4-cidr-blocks" | grep -c '^10\..*' || true)      DNS_CLUSTER_IP=10.100.0.10      if [[ "$TEN_RANGE" != "0" ]]; then        DNS_CLUSTER_IP=172.20.0.10      fi    fi  fielse  DNS_CLUSTER_IP="${DNS_CLUSTER_IP}"fiKUBELET_CONFIG=/etc/kubernetes/kubelet/kubelet-config.jsonecho "$(jq ".clusterDNS=[\"$DNS_CLUSTER_IP\"]" $KUBELET_CONFIG)" &gt; $KUBELET_CONFIGif [[ "${IP_FAMILY}" == "ipv4" ]]; then  INTERNAL_IP=$(imds 'latest/meta-data/local-ipv4')else  INTERNAL_IP_URI=latest/meta-data/network/interfaces/macs/$MAC/ipv6s  INTERNAL_IP=$(imds $INTERNAL_IP_URI)fiINSTANCE_TYPE=$(imds 'latest/meta-data/instance-type')if vercmp "$KUBELET_VERSION" gteq "1.22.0" &amp;&amp; vercmp "$KUBELET_VERSION" lt "1.27.0"; then  # for K8s versions that suport API Priority &amp; Fairness, increase our API server QPS  # in 1.27, the default is already increased to 50/100, so use the higher defaults  echo $(jq ".kubeAPIQPS=( .kubeAPIQPS // 10)|.kubeAPIBurst=( .kubeAPIBurst // 20)" $KUBELET_CONFIG) &gt; $KUBELET_CONFIGfi# Sets kubeReserved and evictionHard in /etc/kubernetes/kubelet/kubelet-config.json for worker nodes. The following two function# calls calculate the CPU and memory resources to reserve for kubeReserved based on the instance type of the worker node.# Note that allocatable memory and CPU resources on worker nodes is calculated by the Kubernetes scheduler# with this formula when scheduling pods: Allocatable = Capacity - Reserved - Eviction Threshold.#calculate the max number of pods per instance typeMAX_PODS_FILE="/etc/eks/eni-max-pods.txt"set +o pipefailMAX_PODS=$(cat $MAX_PODS_FILE | awk "/^${INSTANCE_TYPE:-unset}/"' { print $2 }')set -o pipefailif [ -z "$MAX_PODS" ] || [ -z "$INSTANCE_TYPE" ]; then  log "INFO: No entry for type '$INSTANCE_TYPE' in $MAX_PODS_FILE. Will attempt to auto-discover value."  # When determining the value of maxPods, we're using the legacy calculation by default since it's more restrictive than  # the PrefixDelegation based alternative and is likely to be in-use by more customers.  # The legacy numbers also maintain backwards compatibility when used to calculate `kubeReserved.memory`  MAX_PODS=$(/etc/eks/max-pods-calculator.sh --instance-type-from-imds --cni-version 1.10.0 --show-max-allowed)fi# calculates the amount of each resource to reservemebibytes_to_reserve=$(get_memory_mebibytes_to_reserve $MAX_PODS)cpu_millicores_to_reserve=$(get_cpu_millicores_to_reserve)# writes kubeReserved and evictionHard to the kubelet-config using the amount of CPU and memory to be reservedecho "$(jq '. += {"evictionHard": {"memory.available": "100Mi", "nodefs.available": "10%", "nodefs.inodesFree": "5%"}}' $KUBELET_CONFIG)" &gt; $KUBELET_CONFIGecho "$(jq --arg mebibytes_to_reserve "${mebibytes_to_reserve}Mi" --arg cpu_millicores_to_reserve "${cpu_millicores_to_reserve}m" \  '. += {kubeReserved: {"cpu": $cpu_millicores_to_reserve, "ephemeral-storage": "1Gi", "memory": $mebibytes_to_reserve}}' $KUBELET_CONFIG)" &gt; $KUBELET_CONFIGif [[ "$USE_MAX_PODS" = "true" ]]; then  echo "$(jq ".maxPods=$MAX_PODS" $KUBELET_CONFIG)" &gt; $KUBELET_CONFIGfiKUBELET_ARGS="--node-ip=$INTERNAL_IP --pod-infra-container-image=$PAUSE_CONTAINER --v=2"if vercmp "$KUBELET_VERSION" lt "1.26.0"; then  # TODO: remove this when 1.25 is EOL  KUBELET_CLOUD_PROVIDER="aws"else  KUBELET_CLOUD_PROVIDER="external"  echo "$(jq ".providerID=\"$(provider-id)\"" $KUBELET_CONFIG)" &gt; $KUBELET_CONFIG  # When the external cloud provider is used, kubelet will use /etc/hostname as the name of the Node object.  # If the VPC has a custom `domain-name` in its DHCP options set, and the VPC has `enableDnsHostnames` set to `true`,  # then /etc/hostname is not the same as EC2's PrivateDnsName.  # The name of the Node object must be equal to EC2's PrivateDnsName for the aws-iam-authenticator to allow this kubelet to manage it.  INSTANCE_ID=$(imds /latest/meta-data/instance-id)  # the AWS CLI currently constructs the wrong endpoint URL on localzones (the availability zone group will be used instead of the parent region)  # more info: https://github.com/aws/aws-cli/issues/7043  REGION=$(imds /latest/meta-data/placement/region)  PRIVATE_DNS_NAME=$(AWS_RETRY_MODE=standard AWS_MAX_ATTEMPTS=10 aws ec2 describe-instances --region $REGION --instance-ids $INSTANCE_ID --query 'Reservations[].Instances[].PrivateDnsName' --output text)  KUBELET_ARGS="$KUBELET_ARGS --hostname-override=$PRIVATE_DNS_NAME"fiKUBELET_ARGS="$KUBELET_ARGS --cloud-provider=$KUBELET_CLOUD_PROVIDER"mkdir -p /etc/systemd/systemif [[ "$CONTAINER_RUNTIME" = "containerd" ]]; then  if $ENABLE_DOCKER_BRIDGE; then    log "WARNING: Flag --enable-docker-bridge was set but will be ignored as it's not relevant to containerd"  fi  if [ ! -z "$DOCKER_CONFIG_JSON" ]; then    log "WARNING: Flag --docker-config-json was set but will be ignored as it's not relevant to containerd"  fi  sudo mkdir -p /etc/containerd  sudo mkdir -p /etc/cni/net.d  sudo mkdir -p /etc/systemd/system/containerd.service.d  printf '[Service]\nSlice=runtime.slice\n' | sudo tee /etc/systemd/system/containerd.service.d/00-runtime-slice.conf  if [[ -n "${CONTAINERD_CONFIG_FILE}" ]]; then    sudo cp -v "${CONTAINERD_CONFIG_FILE}" /etc/eks/containerd/containerd-config.toml  fi  sudo sed -i s,SANDBOX_IMAGE,$PAUSE_CONTAINER,g /etc/eks/containerd/containerd-config.toml  echo "$(jq '.cgroupDriver="systemd"' "${KUBELET_CONFIG}")" &gt; "${KUBELET_CONFIG}"  echo "$(jq '.systemReservedCgroup="/system"' "${KUBELET_CONFIG}")" &gt; "${KUBELET_CONFIG}"  echo "$(jq '.kubeReservedCgroup="/runtime"' "${KUBELET_CONFIG}")" &gt; "${KUBELET_CONFIG}"  # Check if the containerd config file is the same as the one used in the image build.  # If different, then restart containerd w/ proper config  if ! cmp -s /etc/eks/containerd/containerd-config.toml /etc/containerd/config.toml; then    sudo cp -v /etc/eks/containerd/containerd-config.toml /etc/containerd/config.toml    sudo cp -v /etc/eks/containerd/sandbox-image.service /etc/systemd/system/sandbox-image.service    sudo chown root:root /etc/systemd/system/sandbox-image.service    systemctl daemon-reload    systemctl enable containerd sandbox-image    systemctl restart sandbox-image containerd  fi  sudo cp -v /etc/eks/containerd/kubelet-containerd.service /etc/systemd/system/kubelet.service  sudo chown root:root /etc/systemd/system/kubelet.service  # Validate containerd config  sudo containerd config dump &gt; /dev/null  # --container-runtime flag is gone in 1.27+  # TODO: remove this when 1.26 is EOL  if vercmp "$KUBELET_VERSION" lt "1.27.0"; then    KUBELET_ARGS="$KUBELET_ARGS --container-runtime=remote"  fielif [[ "$CONTAINER_RUNTIME" = "dockerd" ]]; then  mkdir -p /etc/docker  bash -c "/sbin/iptables-save &gt; /etc/sysconfig/iptables"  cp -v /etc/eks/iptables-restore.service /etc/systemd/system/iptables-restore.service  sudo chown root:root /etc/systemd/system/iptables-restore.service  systemctl daemon-reload  systemctl enable iptables-restore  if [[ -n "$DOCKER_CONFIG_JSON" ]]; then    echo "$DOCKER_CONFIG_JSON" &gt; /etc/docker/daemon.json  fi  if [[ "$ENABLE_DOCKER_BRIDGE" = "true" ]]; then    # Enabling the docker bridge network. We have to disable live-restore as it    # prevents docker from recreating the default bridge network on restart    echo "$(jq '.bridge="docker0" | ."live-restore"=false' /etc/docker/daemon.json)" &gt; /etc/docker/daemon.json  fi  systemctl daemon-reload  systemctl enable docker  systemctl restart dockerelse  log "ERROR: unsupported container runtime: '${CONTAINER_RUNTIME}'"  exit 1fimkdir -p /etc/systemd/system/kubelet.service.dcat &lt;&lt; EOF &gt; /etc/systemd/system/kubelet.service.d/10-kubelet-args.conf[Service]Environment='KUBELET_ARGS=$KUBELET_ARGS'EOFif [[ -n "$KUBELET_EXTRA_ARGS" ]]; then  cat &lt;&lt; EOF &gt; /etc/systemd/system/kubelet.service.d/30-kubelet-extra-args.conf[Service]Environment='KUBELET_EXTRA_ARGS=$KUBELET_EXTRA_ARGS'EOFfisystemctl daemon-reloadsystemctl enable kubeletsystemctl start kubelet# gpu boost clockif command -v nvidia-smi &amp;&gt; /dev/null; then  log "INFO: nvidia-smi found"  nvidia-smi -q &gt; /tmp/nvidia-smi-check  if [[ "$?" == "0" ]]; then    sudo nvidia-smi -pm 1 # set persistence mode    sudo nvidia-smi --auto-boost-default=0    GPUNAME=$(nvidia-smi -L | head -n1)    log "INFO: GPU name: $GPUNAME"    # set application clock to maximum    if [[ $GPUNAME == *"A100"* ]]; then      nvidia-smi -ac 1215,1410    elif [[ $GPUNAME == *"V100"* ]]; then      nvidia-smi -ac 877,1530    elif [[ $GPUNAME == *"K80"* ]]; then      nvidia-smi -ac 2505,875    elif [[ $GPUNAME == *"T4"* ]]; then      nvidia-smi -ac 5001,1590    elif [[ $GPUNAME == *"M60"* ]]; then      nvidia-smi -ac 2505,1177    else      echo "unsupported gpu"    fi  else    log "ERROR: nvidia-smi check failed!"    cat /tmp/nvidia-smi-check  fifilog "INFO: complete!"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> eks </category>
          
      </categories>
      
      
        <tags>
            
            <tag> eks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kubernetes CNI related</title>
      <link href="/2023/07/05/kubernetes-cni-related/"/>
      <url>/2023/07/05/kubernetes-cni-related/</url>
      
        <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2>]]></content>
      
      
      <categories>
          
          <category> eks </category>
          
      </categories>
      
      
        <tags>
            
            <tag> eks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>readiness gate feature test</title>
      <link href="/2023/07/03/readiness-gate-feature-test/"/>
      <url>/2023/07/03/readiness-gate-feature-test/</url>
      
        <content type="html"><![CDATA[<h2 id="readiness-gate-test"><a href="#readiness-gate-test" class="headerlink" title="readiness gate test"></a>readiness gate test</h2><h3 id="prepare-env"><a href="#prepare-env" class="headerlink" title="prepare env"></a>prepare env</h3><pre class="line-numbers language-none"><code class="language-none">k create deployment echo --image xxxxxxxxxxx.dkr.ecr.cn-north-1.amazonaws.com.cn/felixecr:http-echolatest --replicas 4 image source link: hashicorp/http-echo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>this image will listen port 5678 by default *</li></ul><p>modify tags part after creating</p><pre class="line-numbers language-none"><code class="language-none">apiVersion: apps/v1kind: Deploymentmetadata:  annotations:    deployment.kubernetes.io/revision: "2"  labels:    app: echohello  name: echohello  namespace: ingress-nginxspec:  progressDeadlineSeconds: 600  replicas: 4  revisionHistoryLimit: 10  selector:    matchLabels:      app: echohello  strategy:    rollingUpdate:      maxSurge: 25%      maxUnavailable: 25%    type: RollingUpdate  template:    metadata:      creationTimestamp: null      labels:        app: echohello    spec:      containers:      - args:        - -text=hello world        # - "-listen=8080"        image: 543054971342.dkr.ecr.cn-north-1.amazonaws.com.cn/felixecr:http-echolatest        imagePullPolicy: IfNotPresent        name: felixecr        terminationMessagePath: /dev/termination-log        terminationMessagePolicy: File      dnsPolicy: ClusterFirst      restartPolicy: Always      schedulerName: default-scheduler      terminationGracePeriodSeconds: 30<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>create service using below command and then modify the sevice annotations !!!important, do not forget the service type should be  type: LoadBalancer</p><pre class="line-numbers language-none"><code class="language-none">k expose deployment echo --port 5678# Please edit the object below. Lines beginning with a '#' will be ignored,# and an empty file will abort the edit. If an error occurs while saving this file will be# reopened with the relevant failures.#apiVersion: v1kind: Servicemetadata:  annotations:    service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing    service.beta.kubernetes.io/aws-load-balancer-type: external  creationTimestamp: "2023-07-03T07:10:10Z"  labels:    app: echo  name: echo  namespace: default  resourceVersion: "278638"  uid: 141354e1-69f1-415b-81c4-e0f06a704b9cspec:  clusterIP: 172.20.184.156  clusterIPs:  - 172.20.184.156  internalTrafficPolicy: Cluster  ipFamilies:  - IPv4  ipFamilyPolicy: SingleStack  ports:  - port: 5678    protocol: TCP    targetPort: 5678  selector:    app: echo  sessionAffinity: None  type: LoadBalancerstatus:  loadBalancer: {}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>if you want to expose the service as ip target then, check the below annotation<br>service.beta.kubernetes.io/aws-load-balancer-nlb-target-type specifies the target type to configure for NLB. You can choose between instance and ip.</p><blockquote><p>important<br>after testing in aws loadbalancer 2.7 if you edit the service type it won’t create any nlb for you, have to reapply the yaml file</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> eks </category>
          
      </categories>
      
      
        <tags>
            
            <tag> eks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>create a new pods</title>
      <link href="/2023/06/29/create-a-new-pods/"/>
      <url>/2023/06/29/create-a-new-pods/</url>
      
        <content type="html"><![CDATA[<h3 id="创建一个新的pods，具体的流程"><a href="#创建一个新的pods，具体的流程" class="headerlink" title="创建一个新的pods，具体的流程"></a>创建一个新的pods，具体的流程</h3><ol><li>客户端向api server 发送请求创建新的pods</li><li>api server 收到请求后把pods信息存到etcd</li><li>api server 将etcd的内容暴露 这个内容被kube scheduler 监听到</li><li>scheduler 开始尝试给pods 调度到node上， 先是 过滤（各种affinity 和 什么taint之类的） 然后 打分 （ranking）</li><li>scheduler 把结果返回给api server， apiserver会更新信息到etcd ， 更新了一个字段 <pre class="line-numbers language-none"><code class="language-none">- lastProbeTime: null  lastTransitionTime: "2023-06-27T07:17:19Z"  status: "True"  type: PodScheduled<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li>然后节点的kubelet监听api server 发现有pods 该创建，就跟容器运行时去交互，创建对应容器，并且把结果返回给api server</li><li>api server 存储这个信息到etcd ， 这里有个问题， 写到etcd后， “API Server将确认信息发送至Kubelet。” 这句话说的对不对啊。。。</li></ol><p>上边的节点收到了创建pods的的请求之后，的过程<br><a href="https://zhuanlan.zhihu.com/p/438357910">https://zhuanlan.zhihu.com/p/438357910</a></p><ol><li>kubelet监控到有pods 需要创建</li><li>kubelet （grpc client）与cri （grpc server）进行沟通， （如果不能直接沟通，就需要cri shim）</li><li>这里cri会调用到真正的容器服务，一般就是docker或者containerd这里 然后创建真正的容器</li></ol><p>流程图<br><img src="https://raw.githubusercontent.com/Felixlx/images/main/20230629154020.png"></p><p>参考文章<br><a href="https://blog.csdn.net/weixin_40228200">https://blog.csdn.net/weixin_40228200</a></p>]]></content>
      
      
      <categories>
          
          <category> k8s </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>驱逐和抢占</title>
      <link href="/2023/06/27/qu-zhu-he-qiang-zhan/"/>
      <url>/2023/06/27/qu-zhu-he-qiang-zhan/</url>
      
        <content type="html"><![CDATA[<h2 id="pods的驱逐与抢占测试"><a href="#pods的驱逐与抢占测试" class="headerlink" title="pods的驱逐与抢占测试"></a>pods的驱逐与抢占测试</h2><p><a href="https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/pod-priority-preemption/">https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/pod-priority-preemption/</a></p><p>当worker节点压力很大的时候，有pods会处在pending状态，这个时候可能会发生抢占<br>这里有一个很奇怪的现象就是当集群中有pending的pods的时候 如果把aws node干掉了，，，就会调度一个正常得上去，，，然后aws node 会尝试抢占他，，但是因为没有cni，，，所以这个新pod起不来也干不掉，，，aws node就抢不了他，，，，实测这个现象在pending大于1的时候发生，，没有啥例外</p><p>解决方案是干掉kubeproxy 因为他是一个host mode 的网络，，所以能干掉，，然后aws node就上去了，，然后kubeproxy 就能抢一个普通的，，抢回来<br>问题就解决了</p>]]></content>
      
      
      <categories>
          
          <category> eks </category>
          
      </categories>
      
      
        <tags>
            
            <tag> eks </tag>
            
            <tag> k8s </tag>
            
            <tag> aws </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tools link</title>
      <link href="/2023/06/19/tools-link/"/>
      <url>/2023/06/19/tools-link/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="#useful-tools">useful tools</a><ul><li><a href="#convert-curl-command-to-code">convert curl command to code</a></li></ul></li></ul><h2 id="useful-tools"><a href="#useful-tools" class="headerlink" title="useful tools"></a>useful tools</h2><h3 id="convert-curl-command-to-code"><a href="#convert-curl-command-to-code" class="headerlink" title="convert curl command to code"></a>convert curl command to code</h3><p><a href="https://curlconverter.com/">https://curlconverter.com/</a></p><p>find the request in your browser and copy as curl (bash) format</p><p>then it converts to code</p>]]></content>
      
      
      <categories>
          
          <category> tool </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>redis 基础 (ElastiCache)</title>
      <link href="/2023/06/15/redis-ji-chu/"/>
      <url>/2023/06/15/redis-ji-chu/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="#elasticache-redis-%E5%9F%BA%E7%A1%80">elasticache redis 基础</a><ul><li><a href="#%E8%8A%82%E7%82%B9%E7%9B%B8%E5%85%B3">节点相关</a><ul><li><a href="#%E5%8D%95%E8%8A%82%E7%82%B9%E9%87%8D%E5%90%AF%E4%BB%85%E9%99%90%E5%B7%B2%E7%A6%81%E7%94%A8%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F">单节点重启（仅限已禁用集群模式）</a></li><li><a href="#%E8%8A%82%E7%82%B9%E6%9B%BF%E6%8D%A2">节点替换</a></li></ul></li><li><a href="#%E9%9B%86%E7%BE%A4%E7%9B%B8%E5%85%B3">集群相关</a></li></ul></li></ul><h2 id="elasticache-redis-基础"><a href="#elasticache-redis-基础" class="headerlink" title="elasticache redis 基础"></a>elasticache redis 基础</h2><h3 id="节点相关"><a href="#节点相关" class="headerlink" title="节点相关"></a>节点相关</h3><h4 id="单节点重启（仅限已禁用集群模式）"><a href="#单节点重启（仅限已禁用集群模式）" class="headerlink" title="单节点重启（仅限已禁用集群模式）"></a>单节点重启（仅限已禁用集群模式）</h4><ul><li><p>一些更改需要重启集群节点才能应用。例如，对于某些参数，对参数组中参数值的更改仅在重启后才会应用。<br>这个重启如果对象是replica结点的话，那么不会丢失数据！数据会从master 重新复制，这个过程是由aws 完全托管的<br>如果需要重启主节点， 启用故障转移情况下不能提升replica的节点 只能使用主节点故障转移</p></li><li><p>启用集群模式的情况下如果需要修改参数，那就只能手动备份后再还原了，</p></li></ul><p>这两件事儿都参考文档 </p><blockquote><p><a href="https://docs.amazonaws.cn/AmazonElastiCache/latest/red-ug/nodes.rebooting.html">https://docs.amazonaws.cn/AmazonElastiCache/latest/red-ug/nodes.rebooting.html</a></p></blockquote><h4 id="节点替换"><a href="#节点替换" class="headerlink" title="节点替换"></a>节点替换</h4><blockquote><p><a href="https://docs.amazonaws.cn/AmazonElastiCache/latest/red-ug/CacheNodes.NodeReplacement.html">https://docs.amazonaws.cn/AmazonElastiCache/latest/red-ug/CacheNodes.NodeReplacement.html</a></p></blockquote><ul><li>Amazon ElastiCache for Redis 频繁升级其机群，将补丁和升级无缝地应用于实例。但是，我们需要经常重启您的 ElastiCache for Redis 节点，以将必需的操作系统更新应用于底层主机。</li><li>如果自己在计划的替换时间前替换了节点，那么这些更新就会被应用了， 就不用再在计划节点替换的时候搞， 计划就会被取消， 但是有可能收到提醒，，可以忽略</li></ul><h3 id="集群相关"><a href="#集群相关" class="headerlink" title="集群相关"></a>集群相关</h3>]]></content>
      
      
      
        <tags>
            
            <tag> aws </tag>
            
            <tag> redis </tag>
            
            <tag> elasticache </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis 常见问题 (ElastiCache)</title>
      <link href="/2023/06/15/redis-chang-jian-wen-ti/"/>
      <url>/2023/06/15/redis-chang-jian-wen-ti/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> aws </tag>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>aws ElastiCache for reids basic</title>
      <link href="/2023/06/13/aws-elasticache-for-reids-basic/"/>
      <url>/2023/06/13/aws-elasticache-for-reids-basic/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="#aws-elasticache-for-reids-basic">aws ElastiCache for reids basic</a><ul><li><a href="#%E6%9C%AF%E8%AF%AD%E8%AF%B4%E6%98%8E">术语说明</a><ul><li><a href="#%E5%A4%8D%E5%88%B6%E7%BB%84">复制组</a></li></ul></li><li><a href="#%E9%9D%9E%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F">非集群模式</a></li><li><a href="#%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F">集群模式</a></li></ul></li></ul><h2 id="aws-ElastiCache-for-reids-basic"><a href="#aws-ElastiCache-for-reids-basic" class="headerlink" title="aws ElastiCache for reids basic"></a>aws ElastiCache for reids basic</h2><h3 id="术语说明"><a href="#术语说明" class="headerlink" title="术语说明"></a>术语说明</h3><blockquote><p>参考文档 <a href="https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/WhatIs.Components.html#WhatIs.Components.Nodes">https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/WhatIs.Components.html#WhatIs.Components.Nodes</a></p></blockquote><h4 id="复制组"><a href="#复制组" class="headerlink" title="复制组"></a>复制组</h4><ul><li>replication Group： shards implement replicaton by 1 node as read/write Primary and up to 5 other nodes as read-only replicas </li><li>replication Group：A Redis (cluster mode disabled) replication group is a collection of clusters, where one of the clusters is a read/write primary and the others are read-only replicas. Writes to the primary are asynchronously propagated to the replicas.</li><li>自己的理解，replication group 即 复制组，之所以是一个集群的集合，节点=cache cluster，这一点在下边的文档里写了，但是单节点集群是不能叫做复制组的，因为他只有一个节点，这个节点可以叫“cluster”</li><li>复制组本身是一个仅在命令行级别存在的概念，从控制台看到的都叫集群，每一个节点组都叫做分区具体参考下边这个图片 和文档链接</li></ul><p><a href="https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/WhatIs.Terms.html">https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/WhatIs.Terms.html</a></p><p><img src="https://raw.githubusercontent.com/Felixlx/images/main/20230613174742.png"></p><ul><li>cluster： A Redis cluster is a logical grouping of one or more ElastiCache for Redis shards. Data is partitioned across the shards in a Redis (cluster mode enabled) cluster.</li></ul><h3 id="非集群模式"><a href="#非集群模式" class="headerlink" title="非集群模式"></a>非集群模式</h3><ul><li>一个分片最多6节点 1主5复制</li><li>始终只有1个分区</li></ul><h3 id="集群模式"><a href="#集群模式" class="headerlink" title="集群模式"></a>集群模式</h3><ul><li>最多90分片，每一个最多6节点，所以可以有15个主节点加</li></ul>]]></content>
      
      
      <categories>
          
          <category> aws </category>
          
          <category> redis </category>
          
          <category> elasticache </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>k8s的启动过程</title>
      <link href="/2023/06/08/k8s-de-qi-dong/"/>
      <url>/2023/06/08/k8s-de-qi-dong/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="#%E5%8E%9F%E7%94%9Fkubernetes-%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E5%BC%95%E5%AF%BC">原生kubernetes 集群启动引导</a><ul><li><a href="#%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%86%85%E5%AE%B9">官方文档内容</a><ul><li><a href="#tls-%E5%90%AF%E5%8A%A8%E5%BC%95%E5%AF%BC">TLS 启动引导</a></li><li><a href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B">初始化过程</a></li><li><a href="#%E5%90%AF%E5%8A%A8%E5%BC%95%E5%AF%BC%E5%88%9D%E5%A7%8B%E5%8C%96">启动引导初始化</a></li></ul></li></ul></li><li><a href="#eks%E9%9B%86%E7%BE%A4%E7%9A%84kubelet%E5%90%AF%E5%8A%A8%E5%BC%95%E5%AF%BC">eks集群的kubelet启动引导</a></li></ul><h2 id="原生kubernetes-集群启动引导"><a href="#原生kubernetes-集群启动引导" class="headerlink" title="原生kubernetes 集群启动引导"></a>原生kubernetes 集群启动引导</h2><blockquote><p>参考来源 <a href="https://github.com/zhojiew/aws-learning-notebook/blob/main/eks/eks%E8%8A%82%E7%82%B9%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%BC%95%E5%AF%BC%E5%92%8C%E9%89%B4%E6%9D%83%E9%80%BB%E8%BE%91.md">https://github.com/zhojiew/aws-learning-notebook/blob/main/eks/eks%E8%8A%82%E7%82%B9%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%BC%95%E5%AF%BC%E5%92%8C%E9%89%B4%E6%9D%83%E9%80%BB%E8%BE%91.md</a></p></blockquote><img src="https://s2.loli.net/2023/05/20/DwbpckVa9rS37Bg.png" style="zoom:67%;"><p>一切的开始都是kubelet这个服务的启动</p><h3 id="官方文档内容"><a href="#官方文档内容" class="headerlink" title="官方文档内容"></a>官方文档内容</h3><h4 id="TLS-启动引导"><a href="#TLS-启动引导" class="headerlink" title="TLS 启动引导"></a>TLS 启动引导</h4><p>在一个 Kubernetes 集群中，工作节点上的组件（kubelet 和 kube-proxy）需要与 Kubernetes 控制平面组件通信，尤其是 kube-apiserver。 为了确保通信本身是私密的、不被干扰，并且确保集群的每个组件都在与另一个可信的组件通信， 我们强烈建议使用节点上的客户端 TLS 证书。</p><p>启动引导这些组件的正常过程，尤其是需要证书来与 kube-apiserver 安全通信的工作节点， 可能会是一个具有挑战性的过程，因为这一过程通常不受 Kubernetes 控制，需要不少额外工作。 这也使得初始化或者扩缩一个集群的操作变得具有挑战性。</p><p>为了简化这一过程，从 1.4 版本开始，Kubernetes 引入了一个证书请求和签名 API。 该提案可在这里看到。</p><p>本文档描述节点初始化的过程，如何为 kubelet 配置 TLS 客户端证书启动引导， 以及其背后的工作原理。</p><h4 id="初始化过程"><a href="#初始化过程" class="headerlink" title="初始化过程"></a>初始化过程</h4><p>当工作节点启动时，kubelet 执行以下操作：</p><p>寻找自己的 kubeconfig 文件<br>检索 API 服务器的 URL 和凭据，通常是来自 kubeconfig 文件中的 TLS 密钥和已签名证书<br>尝试使用这些凭据来与 API 服务器通信<br>假定 kube-apiserver 成功地认证了 kubelet 的凭据数据，它会将 kubelet 视为一个合法的节点并开始将 Pod 分派给该节点。</p><p>注意，签名的过程依赖于：</p><p>kubeconfig 中包含密钥和本地主机的证书<br>证书被 kube-apiserver 所信任的一个证书机构（CA）所签名<br>负责部署和管理集群的人有以下责任：</p><ul><li>创建 CA 密钥和证书</li><li>将 CA 证书发布到 kube-apiserver 运行所在的控制平面节点上</li><li>为每个 kubelet 创建密钥和证书；强烈建议为每个 kubelet 使用独一无二的、 CN 取值与众不同的密钥和证书</li><li>使用 CA 密钥对 kubelet 证书签名</li><li>将 kubelet 密钥和签名的证书发布到 kubelet 运行所在的特定节点上</li><li>本文中描述的 TLS 启动引导过程有意简化甚至完全自动化上述过程， 尤其是第三步之后的操作，因为这些步骤是初始化或者扩缩集群时最常见的操作。</li></ul><h4 id="启动引导初始化"><a href="#启动引导初始化" class="headerlink" title="启动引导初始化"></a>启动引导初始化</h4><p>在启动引导初始化过程中，会发生以下事情：</p><ul><li>kubelet 启动</li><li>kubelet 看到自己没有对应的 kubeconfig 文件</li><li>kubelet 搜索并发现 bootstrap-kubeconfig 文件</li><li>kubelet 读取该启动引导文件，从中获得 API 服务器的 URL 和用途有限的一个“令牌（Token）”</li><li>kubelet 建立与 API 服务器的连接，使用上述令牌执行身份认证</li><li>kubelet 现在拥有受限制的凭据来创建和取回证书签名请求（CSR）</li><li>kubelet 为自己创建一个 CSR，并将其 signerName 设置为 kubernetes.io/kube-apiserver-client-kubelet</li><li>CSR 被以如下两种方式之一批复：</li><li>如果配置了，kube-controller-manager 会自动批复该 CSR</li><li>如果配置了，一个外部进程，或者是人，使用 Kubernetes API 或者使用 kubectl 来批复该 CSR</li><li>kubelet 所需要的证书被创建</li><li>证书被发放给 kubelet</li><li>kubelet 取回该证书</li><li>kubelet 创建一个合适的 kubeconfig，其中包含密钥和已签名的证书</li><li>kubelet 开始正常操作</li><li>可选地，如果配置了，kubelet 在证书接近于过期时自动请求更新证书</li><li>更新的证书被批复并发放；取决于配置，这一过程可能是自动的或者手动完成<br>本文的其余部分描述配置 TLS 启动引导的必要步骤及其局限性。</li></ul><p>kubelet会寻找kubeconfig文件，如果没找到则</p><ul><li>寻找bootstrap-kubeconfig文件开始引导过程</li><li>使用bootstrap-kubeconfig文件中的api server url和token（有限权限）进行身份认证</li><li>创建和取回证书签名请求（CSR），此时kube-controller-manager会自动批复该 CSR</li><li>kubelet 取回签发的证书，创建 <code>kubeconfig</code>文件，包含密钥和已签名的证书</li></ul><p>在使用kubeadm初始化control plane时日志中的信息和引导配置一致</p><blockquote><p><a href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/#bootstrap-initialization">https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/#bootstrap-initialization</a></p></blockquote><pre class="line-numbers language-none"><code class="language-none">[apiclient] All control plane components are healthy after 15.003839 seconds[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace[kubelet] Creating a ConfigMap "kubelet-config-1.18" in namespace kube-system with the configuration for the kubelets in the cluster[upload-certs] Skipping phase. Please see --upload-certs[bootstrap-token] Using token: 47wg36.zm1tr8lfosat2943[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace[kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>同样，kubelet启动时需要以下参数来完成初始化</p><ul><li><code>--cert-dir="/var/lib/kubelet/pki"</code>，path to store the key and certificate it generates (optional, can use default)</li><li><code>--kubeconfig="/var/lib/kubelet/kubeconfig"</code>，A path to a <code>kubeconfig</code> file that does not yet exist; it will place the bootstrapped config file here</li><li><code>--bootstrap-kubeconfig="/var/lib/kubelet/bootstrap-kubeconfig"</code>，A path to a bootstrap <code>kubeconfig</code> file to provide the URL for the server and bootstrap credentials, e.g. a bootstrap token</li><li>Optional: instructions to rotate certificates</li></ul><p>其中/var/lib/kubelet/bootstrap-kubeconfig文件的内容格式如下</p><ul><li>user字段下使用一个token进行身份认证</li><li>certificate-authority由kubelet用来验证apiserver的服务器证书</li></ul><blockquote><p><a href="https://kubernetes.io/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/#kubelet-configuration">https://kubernetes.io/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/#kubelet-configuration</a></p></blockquote><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Config<span class="token key atrule">clusters</span><span class="token punctuation">:</span><span class="token punctuation">-</span> <span class="token key atrule">cluster</span><span class="token punctuation">:</span>    <span class="token key atrule">certificate-authority</span><span class="token punctuation">:</span> /var/lib/kubernetes/ca.pem    <span class="token key atrule">server</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//my.server.example.com<span class="token punctuation">:</span><span class="token number">6443</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> bootstrap<span class="token key atrule">contexts</span><span class="token punctuation">:</span><span class="token punctuation">-</span> <span class="token key atrule">context</span><span class="token punctuation">:</span>    <span class="token key atrule">cluster</span><span class="token punctuation">:</span> bootstrap    <span class="token key atrule">user</span><span class="token punctuation">:</span> kubelet<span class="token punctuation">-</span>bootstrap  <span class="token key atrule">name</span><span class="token punctuation">:</span> bootstrap<span class="token key atrule">current-context</span><span class="token punctuation">:</span> bootstrap<span class="token key atrule">preferences</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token key atrule">users</span><span class="token punctuation">:</span><span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> kubelet<span class="token punctuation">-</span>bootstrap  <span class="token key atrule">user</span><span class="token punctuation">:</span>    <span class="token key atrule">token</span><span class="token punctuation">:</span> 07401b.f395accd246ae52d<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于<code>kubeconfig</code>文件</p><blockquote><p>在启动 kubelet 时，如果 <code>--kubeconfig</code> 标志所指定的文件并不存在，会使用通过标志 <code>--bootstrap-kubeconfig</code> 所指定的启动引导 kubeconfig 配置来向 API 服务器请求客户端证书。 在证书请求被批复并被 kubelet 收回时，一个引用所生成的密钥和所获得证书的 kubeconfig 文件会被写入到通过 <code>--kubeconfig</code> 所指定的文件路径下。 证书和密钥文件会被放到 <code>--cert-dir</code> 所指定的目录中</p></blockquote><p>引导节点拿到的证书是kubelet客户端证书，用来和apiserver通信。kubelet也可以作为服务向外暴露，证书的来源有</p><ul><li>使用通过 <code>--tls-private-key-file</code> 和 <code>--tls-cert-file</code> 所设置的密钥和证书</li><li>如果没有提供密钥和证书，则创建自签名的密钥和证书</li><li>通过 CSR API 从集群服务器请求服务证书</li></ul><p>配置完成后最终<code>kubelet</code>使用该<code>kubeconfig</code>文件和<code>apiserver</code>通信，注意这个文件名叫做<code>kubelet-client-current.pem</code></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">clusters</span><span class="token punctuation">:</span><span class="token punctuation">-</span> <span class="token key atrule">cluster</span><span class="token punctuation">:</span>    <span class="token key atrule">certificate-authority-data</span><span class="token punctuation">:</span> LS0tLS1CRUdJTiBDRVJUSUZJQ0F<span class="token punctuation">...</span>    <span class="token key atrule">server</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//192.168.1.10<span class="token punctuation">:</span><span class="token number">6443</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> test<span class="token punctuation">-</span>cluster<span class="token key atrule">contexts</span><span class="token punctuation">:</span><span class="token punctuation">-</span> <span class="token key atrule">context</span><span class="token punctuation">:</span>    <span class="token key atrule">cluster</span><span class="token punctuation">:</span> test<span class="token punctuation">-</span>cluster    <span class="token key atrule">user</span><span class="token punctuation">:</span> system<span class="token punctuation">:</span>node<span class="token punctuation">:</span>test<span class="token punctuation">-</span>cluster<span class="token punctuation">-</span>node<span class="token punctuation">-</span><span class="token number">1</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> system<span class="token punctuation">:</span>node<span class="token punctuation">:</span>test<span class="token punctuation">-</span>cluster<span class="token punctuation">-</span>node<span class="token punctuation">-</span><span class="token number">1</span><span class="token key atrule">current-context</span><span class="token punctuation">:</span> system<span class="token punctuation">:</span>node<span class="token punctuation">:</span>test<span class="token punctuation">-</span>cluster<span class="token punctuation">-</span>node<span class="token punctuation">-</span><span class="token number">1</span><span class="token key atrule">kind</span><span class="token punctuation">:</span> Config<span class="token key atrule">preferences</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token key atrule">users</span><span class="token punctuation">:</span><span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> system<span class="token punctuation">:</span>node<span class="token punctuation">:</span>test<span class="token punctuation">-</span>cluster<span class="token punctuation">-</span>node<span class="token punctuation">-</span><span class="token number">1</span>  <span class="token key atrule">user</span><span class="token punctuation">:</span>    <span class="token key atrule">client-certificate</span><span class="token punctuation">:</span> /var/lib/kubelet/pki/kubelet<span class="token punctuation">-</span>client<span class="token punctuation">-</span>current.pem    <span class="token key atrule">client-key</span><span class="token punctuation">:</span> /var/lib/kubelet/pki/kubelet<span class="token punctuation">-</span>client<span class="token punctuation">-</span>current.pem<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="eks集群的kubelet启动引导"><a href="#eks集群的kubelet启动引导" class="headerlink" title="eks集群的kubelet启动引导"></a>eks集群的kubelet启动引导</h2><p>eks节点使用bootstrap启动脚本来完成kubelet的初始化，启动的完整参数如下</p><ul><li><p>没有指定<code>--bootstrap-kubeconfig</code>，意味着不需要进行TLS token的初始化</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">/usr/bin/kubelet --cloud-provider aws --image-credential-provider-config /etc/eks/ecr-credential-provider/ecr-credential-provider-config --image-credential-provider-bin-dir /etc/eks/ecr-credential-provider <span class="token parameter variable">--config</span> /etc/kubernetes/kubelet/kubelet-config.json <span class="token parameter variable">--kubeconfig</span> /var/lib/kubelet/kubeconfig --container-runtime remote --container-runtime-endpoint unix:///run/containerd/containerd.sock --node-ip<span class="token operator">=</span><span class="token number">192.168</span>.27.37 --pod-infra-container-image<span class="token operator">=</span><span class="token number">918309763551</span>.dkr.ecr.cn-north-1.amazonaws.com.cn/eks/pause:3.5 <span class="token parameter variable">--v</span><span class="token operator">=</span><span class="token number">2</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p><code>/var/lib/kubelet/pki/</code>路径下存在证书</p><pre class="line-numbers language-none"><code class="language-none">-rw------- 1 root root 1378 May 20 04:41 kubelet-server-2023-05-20-04-41-35.pemlrwxrwxrwx 1 root root   59 May 20 04:41 kubelet-server-current.pem -&gt; /var/lib/kubelet/pki/kubelet-server-2023-05-20-04-41-35.pem<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><p>我们启动一个新的eks优化ami查看这些路径下有无这些文件，</p><pre class="line-numbers language-none"><code class="language-none">aws ec2 run-instances --image-id ami-0b779da1a68e38cf1 \--instance-type m4.large \--key-name temp-key \--count 1 \    --subnet-id subnet-027025e9d9760acdd \    --security-group-ids sg-096df1a0cb9a6d7e9 \    --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=testena}]' 'ResourceType=volume,Tags=[{Key=Name,Value=testena}]'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>查看<code>kubeconfig</code>实际上是由bootstrap替换得到的</p><pre class="line-numbers language-none"><code class="language-none">$ cat /var/lib/kubelet/kubeconfigapiVersion: v1kind: Configclusters:- cluster:    certificate-authority: /etc/kubernetes/pki/ca.crt    server: MASTER_ENDPOINT  name: kubernetescontexts:- context:    cluster: kubernetes    user: kubelet  name: kubeletcurrent-context: kubeletusers:- name: kubelet  user:    exec:      apiVersion: client.authentication.k8s.io/v1beta1      command: /usr/bin/aws-iam-authenticator      args:        - "token"        - "-i"        - "CLUSTER_NAME"        - --region        - "AWS_REGION"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>/var/lib/kubelet/pki/</code>路径下并无文件，因此实际上是通过kubelet启动时生成的</p><p>通常的eks节点kubelet启动日志</p><p><img src="https://s2.loli.net/2023/05/20/5A7gLKRTDcFYZNt.png"></p><p>我们修改并额外指定kubelet启动参数为<code>/var/lib/kubelet/bootstrap-kubeconfig</code></p><pre class="line-numbers language-none"><code class="language-none">mv /var/lib/kubelet/kubeconfig /var/lib/kubelet/bootstrap-kubeconfigKUBELET_EXTRA_ARGS="--bootstrap-kubeconfig /var/lib/kubelet/bootstrap-kubeconfig $KUBELET_EXTRA_ARGS"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>此时kubelet无法启动，等待客户端证书签发</p><p><img src="https://s2.loli.net/2023/05/20/ZO273rTIkw5AQmF.png"></p><p><code>/var/lib/kubelet/pki/</code>多了一个文件<code>kubelet-client.key.tmp</code></p><ul><li>kubelet生成cliet私钥，使用该私钥生成csr</li><li>之后向apiserver发送csr，请求公钥证书验证签名</li></ul><pre class="line-numbers language-none"><code class="language-none">$ lltotal 8-rw------- 1 root root  227 May 20 05:59 kubelet-client.key.tmp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>再次重启kubelet，仍旧保持同样的结果</p><p><img src="https://s2.loli.net/2023/05/20/FSNUIXKhVBgqvPQ.png"></p><p>手动通过csr</p><pre class="line-numbers language-none"><code class="language-none">$ kubectl get csrnode-csr-NvE0ty-HnP-dA435aze3oo3ubHfHI70ZX_9fTIss0Z0[ec2-user@ip-172-31-22-99 ~]$ kubectl certificate approve node-csr-NvE0ty-HnP-dA435aze3oo3ubHfHI70ZX_9fTIss0Z0certificatesigningrequest.certificates.k8s.io/node-csr-NvE0ty-HnP-dA435aze3oo3ubHfHI70ZX_9fTIss0Z0 approved<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>此时kubelet显示csr已经通过，等待签发证书，但是这一步显然是不行的（可能会绕过sts）</p><pre class="line-numbers language-none"><code class="language-none">"Waiting for client certificate to be issued"certificate signing request node-csr-NvE0ty-HnP-dA435aze3oo3ubHfHI70ZX_9fTIss0Z0 is approved, waiting to be issued<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>由于eks的apiserver我们看不到，因此无从知晓kubelet的集权是怎么完成的，目前推测和serviceaccount类似都是使用webhook的方式完成的。</p><p>接下来，进入节点并停止kubelet服务，手动使用预置参数启动kubelet</p><pre class="line-numbers language-none"><code class="language-none"># /usr/bin/kubelet --config /etc/kubernetes/kubelet/kubelet-config.json --kubeconfig /var/lib/kubelet/kubeconfig --container-runtime-endpoinunix:///run/containerd/containerd.sock --image-credential-provider-config /etc/eks/image-credential-provider/config.json --image-credential-provider-bin-dir /etc/eks/image-credential-provider --node-ip=192.168.31.153 --pod-infra-container-image=918309763551.dkr.ecr.cn-north-1.amazonaws.com.cn/eks/pause:3.5 --v=2 --cloud-provider=aws --container-runtime=remote --node-labels=eks.amazonaws.com/sourceLaunchTemplateVersion=1,alpha.eksctl.io/cluster-name=test124,alpha.eksctl.io/nodegroup-name=test124-ng6,eks.amazonaws.com/nodegroup-image=ami-0b779da1a68e38cf1,eks.amazonaws.com/capacityType=ON_DEMAND,eks.amazonaws.com/nodegroup=test124-ng6,eks.amazonaws.com/sourceLaunchTemplateId=lt-0adf6b991b5366a98 --max-pods=58<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看kubelet日志</p><ul><li><p>确实存在csr申请和kubelet证书签发</p><pre class="line-numbers language-none"><code class="language-none">server.go:1175] "Started kubelet"server.go:155] "Starting to listen" address="0.0.0.0" port=10250...log.go:198] http: TLS handshake error from 192.168.9.40:33148: no serving certificate available for the kubelet...csr.go:261] certificate signing request csr-2blqg is approved, waiting to be issuedcsr.go:257] certificate signing request csr-2blqg is issuedcertificate_manager.go:270] kubernetes.io/kubelet-serving: Certificate expiration is 2024-05-19 08:05:00 +0000 UTC, rotation deadline is 2024-04-09 08:32:10.925495309 +0000 UTCcertificate_manager.go:270] kubernetes.io/kubelet-serving: Waiting 7800h21m57.699693545s for next certificate rotationcertificate_manager.go:270] kubernetes.io/kubelet-serving: Certificate expiration is 2024-05-19 08:05:00 +0000 UTC, rotation deadline is 2024-02-19 02:05:12.905986938 +0000 UTCcertificate_manager.go:270] kubernetes.io/kubelet-serving: Waiting 6593h54m58.680004839s for next certificate rotation<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>查看证书内容，kubelet<code>的用户组是</code>system:nodes， 用户名为system:node:ip-192-168-31-153.cn-north-1.compute.internal。<code>kube-apiserver</code>就可以基于Node Authorizer来限制<code>kubelet</code>只能读取和修改本节点上的资源</p><pre class="line-numbers language-none"><code class="language-none">$ sudo openssl x509 -noout -text -in /var/lib/kubelet/pki/kubelet-server-current.pemCertificate:    Data:        Version: 3 (0x2)        Serial Number:            2c:26:45:8d:d2:56:39:64:33:b4:b0:c6:6f:82:e7:66:14:f7:55:b9    Signature Algorithm: sha256WithRSAEncryption        Issuer: CN=kubernetes        Validity            Not Before: May 20 08:05:00 2023 GMT            Not After : May 19 08:05:00 2024 GMT        Subject: O=system:nodes, CN=system:node:ip-192-168-31-153.cn-north-1.compute.internal        Subject Public Key Info:            Public Key Algorithm: id-ecPublicKey                Public-Key: (256 bit)                pub:                    04:25:36:df:f1:44:30:00:f7:62:43:7a:f3:cc:21:                    22:ee:ed:40:40:0c:0b:28:2c:87:16:4f:bd:9b:c5:                    70:83:e3:15:8a:2c:b9:f1:94:ca:53:95:d8:ee:42:                    b4:21:ab:85:a6:25:0f:71:b8:2d:c6:b2:08:ce:e0:                    d9:d1:c3:87:a0                ASN1 OID: prime256v1                NIST CURVE: P-256<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><p>这之后逻辑上kubelet会使用这个证书访问apiserver，但是实际上并没有用到这个证书。为了验证我们手动将<code>/var/lib/kubelet/pki</code>下的文件全部删除</p><pre class="line-numbers language-none"><code class="language-none">rm -rf /var/lib/kubelet/pki<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>但是经过一段时间后，节点并没有进入not ready状态，并且没有任何影响</p><p>那么接下来的问题在于</p><p>（1）如果不需要客户端证书，那为什么还需要申请呢？</p><p>目前看来是由于kubelet需要对外暴露服务，所以通过 CSR API 从集群服务器请求服务证书</p><blockquote><p><a href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/#client-and-serving-certificates">https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/#client-and-serving-certificates</a></p></blockquote><blockquote><p><code>kubelet</code>同样对外暴露了HTTPS服务，其客户端主要是<code>kube-apiserver</code>和一些监控组件，如<code>metric-server</code>。<code>kube-apiserver</code>需要访问<code>kubelet</code>来获取容器的日志和执行命令（kubectl logs/exec)， 监控组件需要访问<code>kubelet</code>暴露的cadvisor接口来获取监控信息</p><p>在<code>kubelet</code>在启动时，如果没有指定服务端证书路径，会创建一个自签的CA证书，并使用该CA为自己签发服务端证书</p></blockquote><p>在<code>kubelet</code>配置文件配置<code>serverTLSBootstrap</code>为true就可以启用这项特性，在eks节点上kubelet确实配置为<code>"serverTLSBootstrap": true</code></p><p>也就是说，这里为kubelet签发的并不是客户端证书，而是服务端证书。</p><p>（2）eks节点究竟是使用什么来进行apiserver的认证呢？</p><p>上面的分析表明，eks节点不是通过签发客户端证书和apiserver通信的（手动签发实际上会卡在等待issued）。目前唯一能看到的和kubelet与apiserver通信的配置就只有<code>/var/lib/kubelet/kubeconfig</code>文件</p><p>手动修改节点上的default凭证会导致节点进入not ready状态，可能是kubelet在使用<code>/usr/bin/aws-iam-authenticator</code>获取tokne后，请求没有权限导致的。</p><p>我们直接拿<code>/usr/bin/aws-iam-authenticator</code>生成的token请求apiserver</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">/usr/bin/aws-iam-authenticator token <span class="token parameter variable">-i</span> test124<span class="token function">curl</span> <span class="token parameter variable">-k</span> <span class="token parameter variable">--header</span> <span class="token string">"Authorization: Bearer xxxxxxxxxxxxxxxxxxxx"</span> https://C9611E71A15AC11DE8CF33921D4BC09B.yl4.cn-north-1.eks.amazonaws.com.cn<span class="token punctuation">{</span>  <span class="token string">"kind"</span><span class="token builtin class-name">:</span> <span class="token string">"Status"</span>,  <span class="token string">"apiVersion"</span><span class="token builtin class-name">:</span> <span class="token string">"v1"</span>,  <span class="token string">"metadata"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>,  <span class="token string">"status"</span><span class="token builtin class-name">:</span> <span class="token string">"Failure"</span>,  <span class="token string">"message"</span><span class="token builtin class-name">:</span> <span class="token string">"forbidden: User <span class="token entity" title="\&quot;">\"</span>system:node:ip-192-168-31-153.cn-north-1.compute.internal<span class="token entity" title="\&quot;">\"</span> cannot get path <span class="token entity" title="\&quot;">\"</span>/<span class="token entity" title="\&quot;">\"</span>"</span>,  <span class="token string">"reason"</span><span class="token builtin class-name">:</span> <span class="token string">"Forbidden"</span>,  <span class="token string">"details"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>,  <span class="token string">"code"</span><span class="token builtin class-name">:</span> <span class="token number">403</span><span class="token punctuation">}</span><span class="token comment"># 无权限的请求结果</span><span class="token punctuation">{</span>  <span class="token string">"kind"</span><span class="token builtin class-name">:</span> <span class="token string">"Status"</span>,  <span class="token string">"apiVersion"</span><span class="token builtin class-name">:</span> <span class="token string">"v1"</span>,  <span class="token string">"metadata"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>,  <span class="token string">"status"</span><span class="token builtin class-name">:</span> <span class="token string">"Failure"</span>,  <span class="token string">"message"</span><span class="token builtin class-name">:</span> <span class="token string">"Unauthorized"</span>,  <span class="token string">"reason"</span><span class="token builtin class-name">:</span> <span class="token string">"Unauthorized"</span>,  <span class="token string">"code"</span><span class="token builtin class-name">:</span> <span class="token number">401</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>那么接下来的问题在于，为什么修改默认凭证后，过了10-15分钟才会出现无权限的问题</p><p>查看源码有如下描述，可见token的超时时间为15分钟</p><blockquote><p><a href="https://github.com/kubernetes-sigs/aws-iam-authenticator/blob/master/pkg/token/token.go#L82">https://github.com/kubernetes-sigs/aws-iam-authenticator/blob/master/pkg/token/token.go#L82</a></p></blockquote><pre class="line-numbers language-none"><code class="language-none">const (// The sts GetCallerIdentity request is valid for 15 minutes regardless of this parameters value after it has been// signed, but we set this unused parameter to 60 for legacy reasons (we check for a value between 0 and 60 on the// server side in 0.3.0 or earlier).  IT IS IGNORED.  If we can get STS to support x-amz-expires, then we should// set this parameter to the actual expiration, and make it configurable.requestPresignParam = 60// The actual token expiration (presigned STS urls are valid for 15 minutes after timestamp in x-amz-date).presignedURLExpiration = 15 * time.Minutev1Prefix               = "k8s-aws-v1."maxTokenLenBytes       = 1024 * 4clusterIDHeader        = "x-k8s-aws-id"// Format of the X-Amz-Date header used for expiration// https://golang.org/pkg/time/#pkg-constantsdateHeaderFormat   = "20060102T150405Z"kindExecCredential = "ExecCredential"execInfoEnvKey     = "KUBERNETES_EXEC_INFO"stsServiceID       = "sts")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>单纯将kubeconfig文件修改后是不行的，可能是由于kubelet已经将配置文件读取到内存中了，之后手动删除authenticator，发现过一段时间后出现以下报错</p><pre class="line-numbers language-none"><code class="language-none">kubelet_node_status.go:539] "Error updating node status, will retry" err="error getting node \"ip-192-168-13-54.cn-north-1.compute.internal\": Get \"https://xxxxxxxxB.yl4.cn-north-1.eks.amazonaws.com.cn/api/v1/nodes/ip-192-168-13-54.cn-north-1.compute.internal?resourceVersion=0&amp;timeout=10s\": getting credentials: exec: fork/exec /usr/bin/aws-iam-authenticator: no such file or directory"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>同样在检查5次节点状态后超时，可见kubelet确实是通过authenticator的token来与apiserver通信的</p>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> AWS </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>eks常见问题整理</title>
      <link href="/2023/05/23/eks-chang-jian-wen-ti-zong-jie/"/>
      <url>/2023/05/23/eks-chang-jian-wen-ti-zong-jie/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="#eks%E7%9B%B8%E5%85%B3%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98">EKS相关的常见问题</a><ul><li><a href="#%E8%8A%82%E7%82%B9asg%E7%9B%B8%E5%85%B3">节点，ASG相关</a><ul><li><a href="#%E8%8A%82%E7%82%B9%E7%BB%84%E5%90%AF%E5%8A%A8%E6%A8%A1%E6%9D%BF%E7%9A%84%E5%90%88%E5%B9%B6">节点组启动模板的合并</a></li><li><a href="#%E8%8A%82%E7%82%B9%E7%BB%84%E7%9A%84%E5%A4%9A%E5%8F%AF%E7%94%A8%E5%8C%BA%E8%87%AA%E5%8A%A8%E5%B9%B3%E8%A1%A1">节点组的多可用区自动平衡</a></li><li><a href="#%E8%87%AA%E7%AE%A1%E7%90%86%E8%8A%82%E7%82%B9%E7%BB%84%E5%8A%A0%E5%85%A5%E9%9B%86%E7%BE%A4">自管理节点组加入集群</a></li></ul></li><li><a href="#service">service</a><ul><li><a href="#nlb%E7%9A%84%E7%9B%AE%E6%A0%87%E7%9A%84%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%9C%89%E5%A4%B1%E8%B4%A5%E7%9A%84">nlb的目标的健康检查有失败的</a><ul><li><a href="#%E6%9C%89%E5%8F%AF%E8%83%BD%E6%98%AFservice-%E4%B8%AD%E7%9A%84externaltrafficpolicy-%E5%86%99%E7%9A%84local">有可能是service 中的externalTrafficPolicy 写的local</a></li></ul></li></ul></li></ul></li></ul><h2 id="EKS相关的常见问题"><a href="#EKS相关的常见问题" class="headerlink" title="EKS相关的常见问题"></a>EKS相关的常见问题</h2><h3 id="节点，ASG相关"><a href="#节点，ASG相关" class="headerlink" title="节点，ASG相关"></a>节点，ASG相关</h3><h4 id="节点组启动模板的合并"><a href="#节点组启动模板的合并" class="headerlink" title="节点组启动模板的合并"></a>节点组启动模板的合并</h4><p>在eks创建托管节点组使用模板的情况下，eks会为您创建一个新的启动模板，该模板会合并自己的启动模板里的配置和eks的配置，这个启动模板的创建规则遵循文档【1】中的描述，其中着重描述了以下内容：<br>    不要在用户数据中指定任何启动或修改 kubelet 的命令。这是作为 Amazon EKS 合并的用户数据的一部分执行的。<br>     *注 但是这个行为当您在启动模板中指定了ami之后不会自动合并，<br>【1】<a href="https://docs.amazonaws.cn/eks/latest/userguide/launch-templates.html#launch-template-custom-ami">https://docs.amazonaws.cn/eks/latest/userguide/launch-templates.html#launch-template-custom-ami</a> </p><h4 id="节点组的多可用区自动平衡"><a href="#节点组的多可用区自动平衡" class="headerlink" title="节点组的多可用区自动平衡"></a>节点组的多可用区自动平衡</h4><p>因为节点组的后边放的是asg，所以会遵循asg规则，asg会自动平衡，描述如下：</p><blockquote><p>实例启动时，如果您指定多个可用区，会为这些可用区分配所需容量。如果执行扩展操作，Amazon EC2 Auto Scaling 会自动保持您指定的所有可用区的平衡。<br><a href="https://docs.amazonaws.cn/autoscaling/ec2/userguide/auto-scaling-groups.html">https://docs.amazonaws.cn/autoscaling/ec2/userguide/auto-scaling-groups.html</a></p></blockquote><h4 id="自管理节点组加入集群"><a href="#自管理节点组加入集群" class="headerlink" title="自管理节点组加入集群"></a>自管理节点组加入集群</h4><p>自管理节点组加入集群因为缺少了asg的lifecycle hook 无法自动调用对应的sns后边的一系列函数导致不能够使用eks集群中的controller manager这个角色 创建/更新 对应的aws-configmap， 这会导致节点不能加入集群，对应的会在kubelet的日志中报错为 not authorized to list nodes啥的，这种</p><h3 id="service"><a href="#service" class="headerlink" title="service"></a>service</h3><h4 id="nlb的目标的健康检查有失败的"><a href="#nlb的目标的健康检查有失败的" class="headerlink" title="nlb的目标的健康检查有失败的"></a>nlb的目标的健康检查有失败的</h4><h5 id="有可能是service-中的externalTrafficPolicy-写的local"><a href="#有可能是service-中的externalTrafficPolicy-写的local" class="headerlink" title="有可能是service 中的externalTrafficPolicy 写的local"></a>有可能是service 中的externalTrafficPolicy 写的local</h5><p>在 Kubernetes 中，Service 是一种抽象的概念，它可以将应用程序的多个实例绑定到一个统一的 DNS 名称或 IP 地址上，并提供负载均衡和服务发现功能。externalTrafficPolicy 是 Kubernetes 中用于控制 Service 对外流量的负载均衡策略的一个字段，它可以取值为 “Cluster” 或 “Local”，具体含义如下：</p><p>externalTrafficPolicy=Cluster<br>当 externalTrafficPolicy 的值为 “Cluster” 时，Service 会将所有的外部流量发送到集群中的任意一个节点上，并由该节点上的 kube-proxy 进行负载均衡和转发。这种负载均衡策略适用于需要将外部流量均匀分布到整个集群中的场景，但可能会产生一些额外的网络负载和延迟。</p><p>externalTrafficPolicy=Local<br>当 externalTrafficPolicy 的值为 “Local” 时，Service 只会将流量发送到与请求最近的节点上，并由该节点上的 kube-proxy 进行负载均衡和转发。这种负载均衡策略适用于需要将外部流量尽可能快地转发到最近的节点上的场景，可以减少网络负载和延迟。</p><p>需要注意的是，externalTrafficPolicy 字段只对 Service 类型为 NodePort 和 LoadBalancer 的 Service 有效。对于 ClusterIP 类型的 Service，该字段没有任何作用。同时，externalTrafficPolicy 只针对外部流量有效，对于集群内部的流量，负载均衡策略由 kube-proxy 的默认规则决定。</p><p>总的来说，externalTrafficPolicy 是 Kubernetes 中用于控制 Service 对外流量的负载均衡策略的一个字段，可以根据实际需求选择合适的策略，提高网络性能和效率。</p>]]></content>
      
      
      <categories>
          
          <category> AWS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> eks </tag>
            
            <tag> aws </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>快速测试笔记</title>
      <link href="/2023/05/22/kuai-su-ce-shi-bi-ji/"/>
      <url>/2023/05/22/kuai-su-ce-shi-bi-ji/</url>
      
        <content type="html"><![CDATA[<h3 id="event-bridge-快速测试"><a href="#event-bridge-快速测试" class="headerlink" title="event bridge 快速测试"></a>event bridge 快速测试</h3><p>此处测试由于lambda 调用 s3 传文件 都是数据事件，没有可靠的cloud trail 所以不方便（三大数据事件还一个dynamodb）， 所以这里选用iam role 附加策略进行测试<br>创建一个测试角色 general， 然后创建eventbridge rule， 使用下边的事件模式</p><pre class="line-numbers language-none"><code class="language-none">{  "source": ["aws.iam"],  "detail-type": ["AWS API Call via CloudTrail"],  "detail": {    "eventSource": ["iam.amazonaws.com"],    "eventName": ["AttachRolePolicy"],    "requestParameters": {      "roleName": ["general"]    }  }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="eks-相关测试"><a href="#eks-相关测试" class="headerlink" title="eks 相关测试"></a>eks 相关测试</h3><pre class="line-numbers language-none"><code class="language-none">kubectl run entry --image=public.ecr.aws/amazonlinux/amazonlinux:latest --restart=Never -- sh -c "sleep infinity"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="分享一个精准分配内存的pod"><a href="#分享一个精准分配内存的pod" class="headerlink" title="分享一个精准分配内存的pod"></a>分享一个精准分配内存的pod</h4><pre class="line-numbers language-none"><code class="language-none">apiVersion: apps/v1kind: Deploymentmetadata:  namespace: default  name: memallocspec:  selector:    matchLabels:      app: memalloc  replicas: 1  template:    metadata:      labels:        app: memalloc    spec:      containers:      - name: memalloc        image: shijuliu/mem_alloc:v1        args: ["/mem_alloc","200"]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="测试sa"><a href="#测试sa" class="headerlink" title="测试sa"></a>测试sa</h4><pre class="line-numbers language-none"><code class="language-none">apiVersion: v1kind: Podmetadata:  creationTimestamp: null  labels:    run: entry  name: entryspec:  containers:  - args:    - sh    - -c    - sleep infinity    image: public.ecr.aws/amazonlinux/amazonlinux:latest    name: entry    resources: {}  serviceAccountName: felix  dnsPolicy: ClusterFirst  restartPolicy: Neverstatus: {}好用的applysed 's/felix/YOUR_SA/' pods.yaml|kubectl apply -n kube-system -f -<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="获取插件对应版本"><a href="#获取插件对应版本" class="headerlink" title="获取插件对应版本"></a>获取插件对应版本</h4><pre class="line-numbers language-none"><code class="language-none">aws eks describe-addon-versions --kubernetes-version 1.25 --query 'addons[].[addonName,addonVersions[].addonVersion]|[]'output[    "vpc-cni",    [        "v1.12.6-eksbuild.2",        "v1.12.6-eksbuild.1",        "v1.12.5-eksbuild.2",        "v1.12.5-eksbuild.1",        "v1.12.2-eksbuild.1",        "v1.12.0-eksbuild.2",        "v1.11.5-eksbuild.1",        "v1.11.4-eksbuild.3",        "v1.10.4-eksbuild.3"    ],    "aws-ebs-csi-driver",    [        "v1.18.0-eksbuild.1",        "v1.17.0-eksbuild.1",        "v1.16.1-eksbuild.1",        "v1.16.0-eksbuild.1",        "v1.15.1-eksbuild.1",        "v1.15.0-eksbuild.1",        "v1.14.1-eksbuild.1",        "v1.14.0-eksbuild.1",        "v1.13.0-eksbuild.3",        "v1.13.0-eksbuild.2",        "v1.13.0-eksbuild.1",        "v1.12.1-eksbuild.3",        "v1.12.1-eksbuild.2",        "v1.12.1-eksbuild.1",        "v1.11.5-eksbuild.2",        "v1.11.5-eksbuild.1"    ],    "kube-proxy",    [        "v1.25.9-eksbuild.1",        "v1.25.6-eksbuild.2",        "v1.25.6-eksbuild.1",        "v1.24.10-eksbuild.2",        "v1.24.9-eksbuild.1",        "v1.23.16-eksbuild.2",        "v1.23.15-eksbuild.1"    ],    "coredns",    [        "v1.9.3-eksbuild.3",        "v1.9.3-eksbuild.2",        "v1.8.7-eksbuild.4",        "v1.8.7-eksbuild.3",        "v1.8.4-eksbuild.2"    ],    "adot",    [        "v0.74.0-eksbuild.1",        "v0.70.0-eksbuild.1",        "v0.66.0-eksbuild.1",        "v0.62.1-eksbuild.2"    ]]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="nodeshell"><a href="#nodeshell" class="headerlink" title="nodeshell"></a>nodeshell</h4><blockquote><p><a href="https://github.com/zhojiew/aws-learning-notebook/blob/main/eks/%E6%97%A0%E6%B3%95%E7%99%BB%E5%BD%95%E8%8A%82%E7%82%B9%E6%97%B6%E4%BD%BF%E7%94%A8nodeshell%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97.md">https://github.com/zhojiew/aws-learning-notebook/blob/main/eks/%E6%97%A0%E6%B3%95%E7%99%BB%E5%BD%95%E8%8A%82%E7%82%B9%E6%97%B6%E4%BD%BF%E7%94%A8nodeshell%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97.md</a></p></blockquote><p>直接使用特权容器挂载到pods里来获取日志</p><h5 id="使用过程"><a href="#使用过程" class="headerlink" title="使用过程"></a>使用过程</h5><p>在集群中启动如下nodeshell容器，这里可以提前封装好一些组件加速</p><ul><li>pod中使用hostpath挂载了节点的根卷</li><li>将卷挂载到pod中（可写模式）</li></ul><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">annotations</span><span class="token punctuation">:</span>    <span class="token key atrule">kubernetes.io/psp</span><span class="token punctuation">:</span> eks.privileged  <span class="token key atrule">name</span><span class="token punctuation">:</span> k9s<span class="token punctuation">-</span>shell  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> default<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">containers</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">command</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> bash    <span class="token key atrule">image</span><span class="token punctuation">:</span> public.ecr.aws/amazonlinux/amazonlinux<span class="token punctuation">:</span><span class="token number">2</span>    <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent    <span class="token key atrule">name</span><span class="token punctuation">:</span> k9s<span class="token punctuation">-</span>shell    <span class="token key atrule">resources</span><span class="token punctuation">:</span>      <span class="token key atrule">limits</span><span class="token punctuation">:</span>        <span class="token key atrule">cpu</span><span class="token punctuation">:</span> 100m        <span class="token key atrule">memory</span><span class="token punctuation">:</span> 100Mi      <span class="token key atrule">requests</span><span class="token punctuation">:</span>        <span class="token key atrule">cpu</span><span class="token punctuation">:</span> 100m        <span class="token key atrule">memory</span><span class="token punctuation">:</span> 100Mi    <span class="token key atrule">securityContext</span><span class="token punctuation">:</span>      <span class="token key atrule">privileged</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>    <span class="token key atrule">stdin</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>    <span class="token key atrule">terminationMessagePath</span><span class="token punctuation">:</span> /dev/termination<span class="token punctuation">-</span>log    <span class="token key atrule">terminationMessagePolicy</span><span class="token punctuation">:</span> File    <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /host      <span class="token key atrule">name</span><span class="token punctuation">:</span> root<span class="token punctuation">-</span>vol      <span class="token key atrule">readOnly</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>    <span class="token punctuation">-</span> <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /var/run/secrets/kubernetes.io/serviceaccount      <span class="token key atrule">name</span><span class="token punctuation">:</span> kube<span class="token punctuation">-</span>api<span class="token punctuation">-</span>access<span class="token punctuation">-</span>zh92t      <span class="token key atrule">readOnly</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>  <span class="token key atrule">dnsPolicy</span><span class="token punctuation">:</span> ClusterFirst  <span class="token key atrule">enableServiceLinks</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">hostNetwork</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">hostPID</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">nodeName</span><span class="token punctuation">:</span> ip<span class="token punctuation">-</span>192<span class="token punctuation">-</span>168<span class="token punctuation">-</span>6<span class="token punctuation">-</span>84.cn<span class="token punctuation">-</span>north<span class="token punctuation">-</span>1.compute.internal  <span class="token key atrule">preemptionPolicy</span><span class="token punctuation">:</span> PreemptLowerPriority  <span class="token key atrule">priority</span><span class="token punctuation">:</span> <span class="token number">0</span>  <span class="token key atrule">restartPolicy</span><span class="token punctuation">:</span> Never  <span class="token key atrule">schedulerName</span><span class="token punctuation">:</span> default<span class="token punctuation">-</span>scheduler  <span class="token key atrule">securityContext</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>  <span class="token key atrule">serviceAccount</span><span class="token punctuation">:</span> default  <span class="token key atrule">serviceAccountName</span><span class="token punctuation">:</span> default  <span class="token key atrule">terminationGracePeriodSeconds</span><span class="token punctuation">:</span> <span class="token number">0</span>  <span class="token key atrule">tolerations</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">operator</span><span class="token punctuation">:</span> Exists  <span class="token key atrule">volumes</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">hostPath</span><span class="token punctuation">:</span>      <span class="token key atrule">path</span><span class="token punctuation">:</span> /      <span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">""</span>    <span class="token key atrule">name</span><span class="token punctuation">:</span> root<span class="token punctuation">-</span>vol  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> kube<span class="token punctuation">-</span>api<span class="token punctuation">-</span>access<span class="token punctuation">-</span>zh92t    <span class="token key atrule">projected</span><span class="token punctuation">:</span>      <span class="token key atrule">defaultMode</span><span class="token punctuation">:</span> <span class="token number">420</span>      <span class="token key atrule">sources</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token key atrule">serviceAccountToken</span><span class="token punctuation">:</span>          <span class="token key atrule">expirationSeconds</span><span class="token punctuation">:</span> <span class="token number">3607</span>          <span class="token key atrule">path</span><span class="token punctuation">:</span> token      <span class="token punctuation">-</span> <span class="token key atrule">configMap</span><span class="token punctuation">:</span>          <span class="token key atrule">items</span><span class="token punctuation">:</span>          <span class="token punctuation">-</span> <span class="token key atrule">key</span><span class="token punctuation">:</span> ca.crt            <span class="token key atrule">path</span><span class="token punctuation">:</span> ca.crt          <span class="token key atrule">name</span><span class="token punctuation">:</span> kube<span class="token punctuation">-</span>root<span class="token punctuation">-</span>ca.crt      <span class="token punctuation">-</span> <span class="token key atrule">downwardAPI</span><span class="token punctuation">:</span>          <span class="token key atrule">items</span><span class="token punctuation">:</span>          <span class="token punctuation">-</span> <span class="token key atrule">fieldRef</span><span class="token punctuation">:</span>              <span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1              <span class="token key atrule">fieldPath</span><span class="token punctuation">:</span> metadata.namespace            <span class="token key atrule">path</span><span class="token punctuation">:</span> namespace<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>进入到挂载目录并chroot</p><pre class="line-numbers language-none"><code class="language-none">chroot /host<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>使用脚本收集工具收集脚本</p><pre class="line-numbers language-none"><code class="language-none">sudo bash /opt/cni/bin/aws-cni-support.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>授权节点访问s3的权限，并将日志文件上传到s3中</p><pre class="line-numbers language-none"><code class="language-none">sh-4.2# aws s3 cp /var/log/eks_i-09353e3192ec4a400_2023-04-15_0827-UTC_0.7.1.tar.gz s3://temptest/ekslog.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>从s3中下载日志文件并进行之后的排障工作即可</p><h3 id="测试用网站"><a href="#测试用网站" class="headerlink" title="测试用网站"></a>测试用网站</h3><p><a href="https://lightly.teamcode.com/dashboard">https://lightly.teamcode.com/dashboard</a></p>]]></content>
      
      
      <categories>
          
          <category> AWS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 快速测试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kubernetes service account token</title>
      <link href="/2023/05/11/kubernetes-service-account-token/"/>
      <url>/2023/05/11/kubernetes-service-account-token/</url>
      
        <content type="html"><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>从k8s 1.21 开始启用了serviceaccount的BundServiceAccountTokenVolume  功能，这个功能能够自动将sa 给挂载到pods 里并且生成一个token 用于通信， 但是使用这个功能需要 kubernetes client 的版本高于指定版本开发的软件才能用<br>这里的版本是kubernetes clinet而不是其他版本，需要注意。</p><ul><li>Go v0.15.7 及更高版本</li><li>Python v12.0.0 及更高版本</li><li>Java v9.0.0 及更高版本</li><li>Javascript v0.10.3 及更高版本</li><li>Ruby master branch</li><li>Haskell v0.3.0.0</li></ul><p>这个过期时间默认就是1小时（3600秒）更改不了，可以看到在pods 的yaml中被自动添加如下部分：</p><pre class="line-numbers language-none"><code class="language-none">- mountPath: /var/run/secrets/kubernetes.io/serviceaccount  name: kube-api-access-cwbkz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>之后根据这个路径的文件cat 一下就可以用这个去jwt.io进行解码，可以看到warn time 是 iat （issue at） 的一小时之后<br>但是从这个token看不到extend时间， </p><p><img src="https://raw.githubusercontent.com/Felixlx/images/main/20230511174830.png"></p><h3 id="在官方文档里有几个kubeapi的参数"><a href="#在官方文档里有几个kubeapi的参数" class="headerlink" title="在官方文档里有几个kubeapi的参数"></a>在官方文档里有几个kubeapi的参数</h3><p>默认这个最大过期时间是无限，所以能申请无穷大的token</p><pre class="line-numbers language-none"><code class="language-none">--service-account-max-token-expiration durationThe maximum validity duration of a token created by the service account token issuer. If an otherwise valid TokenRequest with a validity duration larger than this value is requested, a token will be issued with a validity duration of this value.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>可以延期的时间，这里eks设置的就是90天，同事忽略上边那个参数，所有的token都是1小时过期之后还能用90天，</p><pre class="line-numbers language-none"><code class="language-none">--service-account-extend-token-expiration     Default: trueTurns on projected service account expiration extension during token generation, which helps safe transition from legacy token to bound service account token feature. If this flag is enabled, admission injected tokens would be extended up to 1 year to prevent unexpected failure during transition, ignoring value of service-account-max-token-expiration.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><blockquote><p><a href="https://v1-23.docs.kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/">https://v1-23.docs.kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/</a></p></blockquote><h3 id="怎么确认是否触发了延长机制"><a href="#怎么确认是否触发了延长机制" class="headerlink" title="怎么确认是否触发了延长机制"></a>怎么确认是否触发了延长机制</h3><p>在aws eks平台，想要查看这个问题可以通过开启审计日志来查看<br>当打开审计日志，同时token超过一小时，就会触发告警，发送到审计日志，具体的查询语句如下</p><pre class="line-numbers language-none"><code class="language-none">fields @timestamp| filter @logStream like /kube-apiserver-audit/| filter @message like /seconds after warning threshold/| parse @message "subject: *, seconds after warning threshold:*\"" as subject, elapsedtime<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p><a href="https://docs.amazonaws.cn/eks/latest/userguide/service-accounts.html#identify-pods-using-stale-tokens">https://docs.amazonaws.cn/eks/latest/userguide/service-accounts.html#identify-pods-using-stale-tokens</a></p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>jq学习中</title>
      <link href="/2023/05/11/jq-xue-xi-zhong/"/>
      <url>/2023/05/11/jq-xue-xi-zhong/</url>
      
        <content type="html"><![CDATA[<h2 id="jq命令的使用"><a href="#jq命令的使用" class="headerlink" title="jq命令的使用"></a>jq命令的使用</h2><h3 id="筛选一个数据并过滤掉空值（处理一次）后为其拼接字符串-前缀"><a href="#筛选一个数据并过滤掉空值（处理一次）后为其拼接字符串-前缀" class="headerlink" title="筛选一个数据并过滤掉空值（处理一次）后为其拼接字符串 (前缀)"></a>筛选一个数据并过滤掉空值（处理一次）后为其拼接字符串 (前缀)</h3><pre class="line-numbers language-none"><code class="language-none">aws ecr list-images --repository-name felixreponame|jq -r '.[]|map(select(.imageTag != null and .imageTag != ""))|map("felixreponame:" + .imageTag)'[  "felixreponame:csi-node-driver-registrarv2.7.0",  "felixreponame:csi-node-driver-registrarv1.3.0",  "felixreponame:testpushlatest",  "felixreponame:felixreponametestpush",  "felixreponame:testpush"]另一个方便的写法aws ecr list-images --repository-name felixecr|jq -r '.[]|map("felixecr:" + (select(.imageTag != null)|.imageTag)|tostring )' |head -5[  "felixecr:csi-node-driver-registrarv2.7.0",  "felixecr:csi-node-driver-registrarv1.3.0",  "felixecr:testpushlatest",  "felixecr:felixecrtestpush",<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>小坑，，，一直尝试join，但是其实在jq里 只是一个把数组拼接的命令<br>join()是jq内置的一个字符串拼接函数，用于将数组元素按照指定的分隔符拼接为一个字符串。以下是join()函数的使用方法：</p><pre class="line-numbers language-none"><code class="language-none">join(separator)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中，separator表示分隔符，可以是任意字符串。join()函数将数组中的所有元素按照分隔符进行拼接，并返回一个新的字符串。例如，以下jq表达式将一个数组中的元素拼接为一个以逗号分隔的字符串：</p><pre class="line-numbers language-none"><code class="language-none">["foo", "bar", "baz"] | join(",")<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>输出结果为：</p><pre class="line-numbers language-none"><code class="language-none">"foo,bar,baz"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在使用join()函数时，需要注意的是，该函数只能用于数组类型的数据，不能用于字符串类型的数据。如果要将一个字符串按照指定分隔符拆分为数组，可以使用split()函数。</p><p>以下是一个示例，用于将一个以空格分隔的字符串拆分为数组，并将数组元素拼接为一个以逗号分隔的字符串：</p><pre class="line-numbers language-none"><code class="language-none">"foo bar baz" | split(" ") | join(",")<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>输出结果为：</p><pre class="line-numbers language-none"><code class="language-none">"foo,bar,baz"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>需要注意的是，在使用join()函数时，如果数组中包含空字符串或null值，这些值将被忽略并不会出现在拼接后的字符串中。如果需要保留这些值，可以使用map()函数将它们转换为特定的字符串或标记，然后再使用join()函数进行拼接。</p><p>例如，以下示例用于将一个数组中的元素拼接为一个以逗号分隔的字符串，并在空字符串和null值处插入标记<empty>：</empty></p><p>json</p><pre class="line-numbers language-none"><code class="language-none">echo ["foo", "", "bar", null, "baz"] | map(if . == "" or . == null then "&lt;empty&gt;" else . end) | join(",")<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>输出结果为：</p><pre class="line-numbers language-none"><code class="language-none">"foo,&lt;empty&gt;,bar,&lt;empty&gt;,baz"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上述示例使用了map()函数，将空字符串和null值转换为<empty>标记，然后使用join()函数将所有元素拼接为一个字符串。</empty></p>]]></content>
      
      
      
        <tags>
            
            <tag> jq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>xray 采样规则测试</title>
      <link href="/2023/05/10/xray-cai-yang-gui-ze-ce-shi/"/>
      <url>/2023/05/10/xray-cai-yang-gui-ze-ce-shi/</url>
      
        <content type="html"><![CDATA[<p>本文follow @zhaojiew 的测试进行，原文连接如下:<br><a href="https://github.com/zhojiew/aws-learning-notebook/blob/main/xray/xray%E9%80%9A%E8%BF%87%E8%AE%BE%E7%BD%AE%E9%87%87%E6%A0%B7%E8%A7%84%E5%88%99%E5%AF%B9%E8%AF%B7%E6%B1%82%E8%BF%9B%E8%A1%8C%E8%BF%87%E6%BB%A4.md">https://github.com/zhojiew/aws-learning-notebook/blob/main/xray/xray%E9%80%9A%E8%BF%87%E8%AE%BE%E7%BD%AE%E9%87%87%E6%A0%B7%E8%A7%84%E5%88%99%E5%AF%B9%E8%AF%B7%E6%B1%82%E8%BF%9B%E8%A1%8C%E8%BF%87%E6%BB%A4.md</a></p><pre class="line-numbers language-none"><code class="language-none"><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="初始化环境-安装npm"><a href="#初始化环境-安装npm" class="headerlink" title="初始化环境 安装npm"></a>初始化环境 安装npm</h3><pre class="line-numbers language-none"><code class="language-none">npm init -ynpm install aws-xray-sdknpm install aws-sdknpm install express<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="起一个express-server测试"><a href="#起一个express-server测试" class="headerlink" title="起一个express server测试"></a>起一个express server测试</h3><pre class="line-numbers language-none"><code class="language-none">// app.jsvar AWSXRay = require('aws-xray-sdk');// xray将aws sdk包装var AWS = AWSXRay.captureAWS(require('aws-sdk'));// var AWS = require('aws-sdk');// AWSXRay.config([AWSXRay.plugins.EC2Plugin, AWSXRay.plugins.ElasticBeanstalkPlugin]);AWS.config.update({ region: 'cn-north-1' });// 指定xray守护进程监听地址AWSXRay.setDaemonAddress('127.0.0.1:2000');const express = require('express')const app = express()const port = 3000app.use(AWSXRay.express.openSegment('TestPathApp'));app.get('/', (req, res) =&gt; {    var document = AWSXRay.getSegment();    // 添加注释和元数据    document.addAnnotation("mykey", "my value");    document.addMetadata("my key", "my value", "my namespace");    res.send('Hello World!')    var s3 = new AWS.S3();    var params = {};    s3.listBuckets(params, function (err, data) {        if (err) console.log(err, err.stack);        else console.log(data);    });})app.get('/testpath', (req, res) =&gt; {    res.send('test path!')})app.use(AWSXRay.express.closeSegment());app.listen(port, () =&gt; {    console.log(`Example app listening on port ${port}`)})<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="开始测试"><a href="#开始测试" class="headerlink" title="开始测试"></a>开始测试</h3><p>为了让xray获取正确权限（没绑定instance profile所以直接命令启动）</p><pre class="line-numbers language-none"><code class="language-none">/usr/bin/xrayfor i in `seq 1 10000`; do curl localhost:3000/ ; curl localhost:3000/testpath ; sleep 0.2; done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="配置采样规则"><a href="#配置采样规则" class="headerlink" title="配置采样规则"></a>配置采样规则</h3><blockquote><blockquote><p><a href="https://docs.aws.amazon.com/zh_cn/xray/latest/devguide/xray-console-sampling.html">https://docs.aws.amazon.com/zh_cn/xray/latest/devguide/xray-console-sampling.html</a><br><a href="https://docs.aws.amazon.com/zh_cn/xray/latest/devguide/xray-sdk-nodejs.html">https://docs.aws.amazon.com/zh_cn/xray/latest/devguide/xray-sdk-nodejs.html</a></p></blockquote></blockquote><h3 id="设置采样限制"><a href="#设置采样限制" class="headerlink" title="设置采样限制"></a>设置采样限制</h3><p>reservoir，每秒钟请求的采样数量<br>fixed rate，超出reservoir之后，对额外请求的百分比<br>举例，存储器容量为50，百分比为10%，如果总体请求为100，则每秒钟的采样数量为50+(100-50)*10%=55</p><p>比如 关掉默认的采样规则（都设置0，0）设置200 的优先级 采样规则匹配指定路径，这个设置0，0 然后设置400的采样规则代替默认，由于先匹配200 规则，就能够过滤掉不想要的路径的追踪</p><pre class="line-numbers language-none"><code class="language-none"><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> xray, js </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>karpenter 安装使用</title>
      <link href="/2023/05/10/karpenter-an-zhuang-shi-yong/"/>
      <url>/2023/05/10/karpenter-an-zhuang-shi-yong/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文内容非常基础，就是熟悉一下写博客，建议不用看，就是一些官方文档内容  </p></blockquote><h2 id="karpenter-install"><a href="#karpenter-install" class="headerlink" title="karpenter install"></a>karpenter install</h2><pre class="line-numbers language-none"><code class="language-none">export KARPENTER_VERSION=v0.27.3export CLUSTER_NAME="${USER}-karpenter-demo"export AWS_DEFAULT_REGION="cn-north-1"export AWS_ACCOUNT_ID="$(aws sts get-caller-identity --query Account --output text)"export TEMPOUT=$(mktemp)echo $KARPENTER_VERSION $CLUSTER_NAME $AWS_DEFAULT_REGION $AWS_ACCOUNT_ID $TEMPOUT<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">curl -fsSL https://karpenter.sh/"${KARPENTER_VERSION}"/getting-started/getting-started-with-karpenter/cloudformation.yaml  &gt; $TEMPOUT &amp;&amp; aws cloudformation deploy   --stack-name "Karpenter-${CLUSTER_NAME}"   --template-file "${TEMPOUT}"   --capabilities CAPABILITY_NAMED_IAM   --parameter-overrides "ClusterName=${CLUSTER_NAME}"eksctl create cluster -f - &lt;&lt;EOF---apiVersion: eksctl.io/v1alpha5kind: ClusterConfigmetadata:  name: ${CLUSTER_NAME}  region: ${AWS_DEFAULT_REGION}  version: "1.24"  tags:    karpenter.sh/discovery: ${CLUSTER_NAME}iam:  withOIDC: true  serviceAccounts:  - metadata:      name: karpenter      namespace: karpenter    roleName: ${CLUSTER_NAME}-karpenter    attachPolicyARNs:    - arn:aws-cn:iam::${AWS_ACCOUNT_ID}:policy/KarpenterControllerPolicy-${CLUSTER_NAME}    roleOnly: trueiamIdentityMappings:- arn: "arn:aws-cn:iam::${AWS_ACCOUNT_ID}:role/KarpenterNodeRole-${CLUSTER_NAME}"  username: system:node:{{EC2PrivateDNSName}}  groups:  - system:bootstrappers  - system:nodesmanagedNodeGroups:- instanceType: m5.large  amiFamily: AmazonLinux2  name: ${CLUSTER_NAME}-ng  desiredCapacity: 2  minSize: 1  maxSize: 10## Optionally run on fargate# fargateProfiles:# - name: karpenter#  selectors:#  - namespace: karpenterEOFexport CLUSTER_ENDPOINT="$(aws eks describe-cluster --name ${CLUSTER_NAME} --query "cluster.endpoint" --output text)"export KARPENTER_IAM_ROLE_ARN="arn:aws-cn:iam::${AWS_ACCOUNT_ID}:role/${CLUSTER_NAME}-karpenter"echo $CLUSTER_ENDPOINT $KARPENTER_IAM_ROLE_ARN<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">aws iam create-service-linked-role --aws-service-name spot.amazonaws.com || true# If the role has already been successfully created, you will see:# An error occurred (InvalidInput) when calling the CreateServiceLinkedRole operation: Service role name AWSServiceRoleForEC2Spot has been taken in this account, please try a different suffix.docker logout public.ecr.awshelm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter --version ${KARPENTER_VERSION} --namespace karpenter --create-namespace   --set serviceAccount.annotations."eks\.amazonaws\.com/role-arn"=${KARPENTER_IAM_ROLE_ARN}   --set settings.aws.clusterName=${CLUSTER_NAME}   --set settings.aws.defaultInstanceProfile=KarpenterNodeInstanceProfile-${CLUSTER_NAME}   --set settings.aws.interruptionQueueName=${CLUSTER_NAME}   --set controller.resources.requests.cpu=1   --set controller.resources.requests.memory=1Gi   --set controller.resources.limits.cpu=1   --set controller.resources.limits.memory=1Gi   --wait<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-none"><code class="language-none">cat &lt;&lt;EOF | kubectl apply -f -apiVersion: karpenter.sh/v1alpha5kind: Provisionermetadata:  name: defaultspec:  requirements:    - key: karpenter.sh/capacity-type      operator: In      values: ["spot"]  limits:    resources:      cpu: 1000  providerRef:    name: default  ttlSecondsAfterEmpty: 30---apiVersion: karpenter.k8s.aws/v1alpha1kind: AWSNodeTemplatemetadata:  name: defaultspec:  subnetSelector:    karpenter.sh/discovery: ${CLUSTER_NAME}  securityGroupSelector:    karpenter.sh/discovery: ${CLUSTER_NAME}EOF测试deploymentcat &lt;&lt;EOF | kubectl apply -f -apiVersion: apps/v1kind: Deploymentmetadata:  name: inflatespec:  replicas: 0  selector:    matchLabels:      app: inflate  template:    metadata:      labels:        app: inflate    spec:  nodeSelector:disktype: ssd      terminationGracePeriodSeconds: 0      containers:        - name: inflate          image: public.ecr.aws/eks-distro/kubernetes/pause:3.7          resources:            requests:              cpu: 1EOFkubectl scale deployment inflate --replicas 5<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>偷跑节点组<br>由于eks控制台展示的数据是从集群内部获取的，因此当使用provisoner创建节点的时候可以打标签偷跑，<br>eks.amazonaws.com/nodegroup=ec2-user-karpenter-demo-ng<br>测试一下就是这个标签</p><pre class="line-numbers language-none"><code class="language-none">  5 apiVersion: karpenter.sh/v1alpha5  6 kind: Provisioner  7 metadata:  8   annotations:  9     kubectl.kubernetes.io/last-applied-configuration: | 10       {"apiVersion":"karpenter.sh/v1alpha5","kind":"Provisioner","metadata":{"annotations":{},"name":"default"},"spec":{"limits":{"resources":{"cpu":1000}},"providerRef":{"name":"default"},"requirements":[{"key":"karpenter.sh/capacity-type","operator":"In","values":["spot"]}],"ttlSecondsAfterEmpty":30}} 11   creationTimestamp: "2023-05-09T14:37:27Z" 12   generation: 3 13   name: default 14   resourceVersion: "337668" 15   uid: c132ec6f-06ae-4153-ad87-2eaf2de7ee6e 16 spec: 17   labels: 18     alpha.eksctl.io/nodegroup-name: ec2-user-karpenter-demo-ng 19     eks.amazonaws.com/nodegroup: ec2-user-karpenter-demo-ng 20   limits: 21     resources: 22       cpu: 1k 23   providerRef: 24     name: default 25   requirements: 26   - key: karpenter.sh/capacity-type 27     operator: In 28     values: 29     - spot 30   - key: kubernetes.io/os 31     operator: In 32     values: 33     - linux 34   - key: kubernetes.io/arch 35     operator: In 36     values: 37     - amd64 38   - key: karpenter.k8s.aws/instance-category 39     operator: In 40     values: 41     - c 42     - m 43     - r 44   - key: karpenter.k8s.aws/instance-generation 45     operator: Gt 46     values: 47     - "2" 48   ttlSecondsAfterEmpty: 30 49 status: 50   resources: 51     attachable-volumes-aws-ebs: "78" 52     cpu: "20" 53     ephemeral-storage: 41918424Ki 54     memory: 46104900Ki 55     pods: "292"~<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> karpenter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一点小知识</title>
      <link href="/2023/05/07/yi-dian-xiao-zhi-shi/"/>
      <url>/2023/05/07/yi-dian-xiao-zhi-shi/</url>
      
        <content type="html"><![CDATA[<h3 id="eks中启用secret加密"><a href="#eks中启用secret加密" class="headerlink" title="eks中启用secret加密"></a>eks中启用secret加密</h3><blockquote><p>eks可以启用为集群中加密的功能，这个功能能够确保 <em>合规性</em> ，同时不需要用户介入操作</p></blockquote><p>使用方法很简单，用户有 create grant的权限就能够为eks集群启用<br>启用过后可以看到一个creategrant的cloudtrail，这时候再用命令创建secret就能够实现自动加密<br>这里的坑是说不能删除这个key 同时不能手动revoke这个grant 否则即便加回来也不能正常使用了， 这里怀疑跟信封加密或者主密钥在eks的缓存相关，未验证。</p><pre class="line-numbers language-none"><code class="language-none">删了grant报错如下 k create secret generic --from-literal i=b testierror: failed to create secret Internal error occurred: rpc error: code = DeadlineExceeded desc = latest balancer error: connection error: desc = "transport: Error while dialing dial unix /var/run/kmsplugin/socket.sock: connect: no such file or directory"[ec2-user@ip-10-0-0-34 ~]$ k create secret generic --from-literal i=b testierror: failed to create secret Internal error occurred: rpc error: code = DeadlineExceeded desc = latest balancer error: connection error: desc = "transport: Error while dialing dial unix /var/run/kmsplugin/socket.sock: connect: no such file or directory"[ec2-user@ip-10-0-0-34 ~]$ k create secret generic --from-literal i=b testierror: failed to create secret Internal error occurred: rpc error: code = DeadlineExceeded desc = latest balancer error: connection error: desc = "transport: Error while dialing dial unix /var/run/kmsplugin/socket.sock: connect: no such file or directory"[ec2-user@ip-10-0-0-34 ~]$ k get secrets testh -o yamlapiVersion: v1data:  h: Yg==kind: Secretmetadata:  creationTimestamp: "2023-05-06T10:06:50Z"  name: testh  namespace: default  resourceVersion: "82014"  uid: 8ce8f4e0-c266-4ae7-b42b-27e24821415etype: Opaque把那个grant手动加回来报错如下[ec2-user@ip-10-0-0-34 ~]$ k create secret generic --from-literal i=b testierror: failed to create secret Internal error occurred: rpc error: code = Unknown desc = failed to encrypt AccessDeniedException:        status code: 400, request id: 2221568f-8f6e-44ce-ac5f-fcd34a571548[ec2-user@ip-10-0-0-34 ~]$ client_loop: send disconnect: Connection reset<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>题外话 eks中的crt解密命令</p></blockquote><pre class="line-numbers language-none"><code class="language-none">echo -n "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJek1EVXlNVEF3TVRReU0xb1hEVE16TURVeE9EQXdNVFF5TTFvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTUpTCkF2WmZucXd0K1JncmthdDBxUURFZmxjd0w3M24wbVcyS2ltcXZ0VU1HQWVFNUV6YmlGU0FWeS9KeHdFYk1TOHAKbm1PT3hQWW01VFZMS2JQOFJaYWJ1bkpSVFRaRy9YZzhxZlplbGZSTy9GTlB1MnJqcnp1UzVlYXJheGhmaVZLcApVVGROZ1RsN0R5V2E5R1RMWU5iMjFocFZJbkFnOEEzS2RXUk9IQ0xjYUtpRHNJTC9GMmt4ajBETzFHc0ZTcSt3Cm1wUGhMN3lYeUFwNFdMRXhOWjMwb3FycHJ6Y3lxT2JrTFJiL0J5dzZ4MmxTMStoSkZ5MkRHa1RKYWxlZ2lQdy8KcnJ0VlV6eU1idFBUNEsxRW9qVzRvMXpoeHFOOUVmMnJlMWpPZG9lL01hajZLREE3Rjd3bWRLNmlGUW9RWGkrUwptR2ZWOWdNU21odmxFRFg1bEY4Q0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZCbWNxdGlnb2Z5bzJPK2NlWDdtdlMwWlM0VGtNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBSTJUbUtqUk5lZ01vT3hzVkduMApyWFBRbGEzQkc0clUxemVjQnMzQ3krSUVqTmM2U0xXQnhwVnlPQzIyaEh2U1dmWHI5ckdpUzJ0dXJGdlVKYUIvCjVtTStrUWh0STZ6ZVlvMzlFYjNoUTFQaCtNVkM5UGtvK1dkWEJ0dS9jRHFMTUF6WjlFSWhCM25RMnNhd0ZjbFYKcDUwOFlPWU0vNU80QjdDVUZJYzExK0FtdmJiTVNDWXBDMTJDNzlLOEgvVU9KY1pKS1UxUGRLNVllZUdqTUp0RQpFM1c5cWZHZ01NeUJFS0QzcCt3MEpuSGRNM0pMUXArR1M5bzBQWFd3czFUZlIycjAxek81MjdVYlE5a1hweGt5CjFSZ1BBU3p5VjFTMmQvd0pxeldCUi9mMERUdWZDSTZYSmN2QlRkNGFJZzJUTm9LUUUvWlI5U2prV2IrMFFSSVAKdVRVPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg=="|base64 -d | openssl x509  -text -noout<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 未完待续 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> eks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tittle test</title>
      <link href="/2023/05/04/first-page/"/>
      <url>/2023/05/04/first-page/</url>
      
        <content type="html"><![CDATA[<h1 id="一级标题测试"><a href="#一级标题测试" class="headerlink" title="一级标题测试"></a>一级标题测试</h1><h2 id="二级标题测试"><a href="#二级标题测试" class="headerlink" title="二级标题测试"></a>二级标题测试</h2><h6 id="六级测试"><a href="#六级测试" class="headerlink" title="六级测试"></a>六级测试</h6><p><em>加粗测试</em></p><table><thead><tr><th>table</th><th>测试</th></tr></thead><tbody><tr><td>分割</td><td>1</td></tr></tbody></table><p>换行测试</p><pre class="line-numbers language-none"><code class="language-none">code test<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> tf </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/04/28/hello-world/"/>
      <url>/2023/04/28/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
